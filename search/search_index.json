{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome This site contains documentation about how to add a new infrastructure provider to the OpenShift platform. To begin learning about the process, please see the Overview .","title":"Welcome"},{"location":"#welcome","text":"This site contains documentation about how to add a new infrastructure provider to the OpenShift platform. To begin learning about the process, please see the Overview .","title":"Welcome"},{"location":"overview/","text":"Overview This document provides a high level view of the workflow for adding a new infrastructure provider to OpenShift. The following list is meant to give a general idea of the work involved with this process, the links contained within the list reference documents with greater detail for each step. Workflow Preparation Start with an idea to add a new infrastructure provider to OpenShift. Identify contacts within Red Hat, and the community, and then set expectations about the process ahead. Information Gathering Define the reference architecture and toplogy for OpenShift clusters on the new provider. Inventory existing components including licenses and plugin providers, and identify supported formats and infrastructure. OpenShift Enhancement Create an enhancment describing the new platform in detail, this will become a part of the official OpenShift enhancements . RHCOS Add support for the new platform to the Red Hat CoreOS Operating System. Installer New platforms should add support the OpenShift Installer, which users use to configure and build their OpenShift clusters. The Installer takes configuration and cloud credentials, validates the information, and builds the cloud infrastructure to create a cluster. Cloud Controller Manager New providers must have a Cloud Controller Manager integrated into OpenShift, including a repository in the OpenShift organization and container images included in the release payload. Container Storage Interface Driver Providers that expose storage options must have a CSI driver integrated into OpenShift, including a repository in the OpenShift organization and container images inclujded in the release payload. Machine API Controllers New providers must have a Machine actuator, and related controllers, for the Machine API Operator , including a repository in the OpenShift organization and container images included in the release payload. Network Ingress and DNS Evaluate provider-specific support for ingress load balancers and endpoint publishing strategies, as well as internal and external DNS support. Update and validate the Cluster Ingress Operator for the new infrastructure provider. Continuous Integration and Testing All components must have a suite of automation including unit style testing (run in isolation), and integration testing (run on cluster from the provider). This automation is part of the OpenShift development and release process, and exists within the OpenShift organization. Component Infrastructure Once OpenShift can be installed and operated on the new infrastructure platform attention should be given to the dynamic infrastructure services. These components are non-critical to the installation process and include things like the image registry. Documentation Product documentation is required for installation and maintenance tasks on the new infrastructure platform. Source level documentation is expected for all component repositories added to the OpenShift organization. Red Hat Relationship After the new infrastructure provider is ready for release, what are the commitments around maintenance and future releases. Release What to do once the code is approved and the release is ready for public consumption. How to promote and advertise, and work with Red Hat.","title":"Overview"},{"location":"overview/#overview","text":"This document provides a high level view of the workflow for adding a new infrastructure provider to OpenShift. The following list is meant to give a general idea of the work involved with this process, the links contained within the list reference documents with greater detail for each step.","title":"Overview"},{"location":"overview/#workflow","text":"Preparation Start with an idea to add a new infrastructure provider to OpenShift. Identify contacts within Red Hat, and the community, and then set expectations about the process ahead. Information Gathering Define the reference architecture and toplogy for OpenShift clusters on the new provider. Inventory existing components including licenses and plugin providers, and identify supported formats and infrastructure. OpenShift Enhancement Create an enhancment describing the new platform in detail, this will become a part of the official OpenShift enhancements . RHCOS Add support for the new platform to the Red Hat CoreOS Operating System. Installer New platforms should add support the OpenShift Installer, which users use to configure and build their OpenShift clusters. The Installer takes configuration and cloud credentials, validates the information, and builds the cloud infrastructure to create a cluster. Cloud Controller Manager New providers must have a Cloud Controller Manager integrated into OpenShift, including a repository in the OpenShift organization and container images included in the release payload. Container Storage Interface Driver Providers that expose storage options must have a CSI driver integrated into OpenShift, including a repository in the OpenShift organization and container images inclujded in the release payload. Machine API Controllers New providers must have a Machine actuator, and related controllers, for the Machine API Operator , including a repository in the OpenShift organization and container images included in the release payload. Network Ingress and DNS Evaluate provider-specific support for ingress load balancers and endpoint publishing strategies, as well as internal and external DNS support. Update and validate the Cluster Ingress Operator for the new infrastructure provider. Continuous Integration and Testing All components must have a suite of automation including unit style testing (run in isolation), and integration testing (run on cluster from the provider). This automation is part of the OpenShift development and release process, and exists within the OpenShift organization. Component Infrastructure Once OpenShift can be installed and operated on the new infrastructure platform attention should be given to the dynamic infrastructure services. These components are non-critical to the installation process and include things like the image registry. Documentation Product documentation is required for installation and maintenance tasks on the new infrastructure platform. Source level documentation is expected for all component repositories added to the OpenShift organization. Red Hat Relationship After the new infrastructure provider is ready for release, what are the commitments around maintenance and future releases. Release What to do once the code is approved and the release is ready for public consumption. How to promote and advertise, and work with Red Hat.","title":"Workflow"},{"location":"cloud-controller-manager/","text":"Cloud Controller Manager This document describes the necessary changes that must be made to add a new Cloud Controller Manager (CCM) to OpenShift. It does not cover the details of writing a CCM, for information about implementing the controller please see the official Kubernetes documentation on Developing Cloud Controller Manager as a starting point. Add the CCM repository to OpenShift One of the first things to do is copy the source code into the OpenShift organization on GitHub. This process is described in more detail in the Creating a GitHub Repository in the OpenShift Organization document. Having the source code in the OpenShift organization will allow Red Hat's continuous integration tooling access to it for running tests, building images, and including in the official releases. Configure basic repository integrations After setting up the code repository, there are several continuous integration tasks which must be done. This process is described in more detail in the Configuring Basic Repository Integrations document. As an example, here is the pull request to add the CCM for Alibaba Cloud to the OpenShift Prow. It configures the Tide mechanics as well as a pre-submit job to check the Go language formatting and a post-submit job to build the container images. openshift/release #19947 Integrating with other OpenShift components In OpenShift there are several operators which work together to ensure that the CCM is properly configured and also that new nodes which join the cluster are similarly configured for the infrastructure provider. To ensure that the new CCM and provider are properly recognized by all components there are several repositories which must be modified. openshift/api Before progressing with the OpenShift integrations, the new infrastructure provider will need to be present in the OpenShift API as part of the infrastructure.config.openshift.io definition. TODO: add link to installer doc step that describes updating openshift/api openshift/library-go In order for the new infrastructure provider to be recognized by the Cluster Cloud Controller Manager Operator, and other operators, the OpenShift library-go project must be updated so that the IsCloudProviderExternal function returns the proper response. As an example, here is the pull request to update the IsCloudProviderExternal function to add support for IBM Cloud. openshift/library-go #1161 It is important to note that any changes to library-go must be vendored into the projects which are dependent upon library-go. This process can often involve several repositories that must be updated before all the components will work together. To make tracking these changes easier, an issue can be used to monitor the individual changes. For example, this is an issue which tracked changes for the GCP and vSphere updates: openshift/cluster-cloud-controller-manager-operator #135 openshift/cluster-cloud-controller-manager-operator OpenShift uses the Cluster Cloud Controller Manager Operator (CCCMO) to manage the deployment and maintenance of the CCMs. This operator will deploy the individual containers of the CCM and ensure their health and continued operation during the cluster lifecycle. Adding a new infrastructure provider will require creating a package within the CCCMO that will contain the code for deploying the new components as well as the templated manifests for them. For a deeper discussion of integrating with the CCCMO, please see the developer documenation from that repository. As an example, here are two pull requests that added the IBM Cloud CCM to the CCCMO. The first pull request adds the primary code changes and manifests for deployment. The second pull request adds the CCM image references for the CCCMO to utilize when deploying from an OpenShift release payload. openshift/cluster-cloud-controller-manager-operator #97 openshift/cluster-cloud-controller-manager-operator #105","title":"Cloud Controller Manager"},{"location":"cloud-controller-manager/#cloud-controller-manager","text":"This document describes the necessary changes that must be made to add a new Cloud Controller Manager (CCM) to OpenShift. It does not cover the details of writing a CCM, for information about implementing the controller please see the official Kubernetes documentation on Developing Cloud Controller Manager as a starting point.","title":"Cloud Controller Manager"},{"location":"cloud-controller-manager/#add-the-ccm-repository-to-openshift","text":"One of the first things to do is copy the source code into the OpenShift organization on GitHub. This process is described in more detail in the Creating a GitHub Repository in the OpenShift Organization document. Having the source code in the OpenShift organization will allow Red Hat's continuous integration tooling access to it for running tests, building images, and including in the official releases.","title":"Add the CCM repository to OpenShift"},{"location":"cloud-controller-manager/#configure-basic-repository-integrations","text":"After setting up the code repository, there are several continuous integration tasks which must be done. This process is described in more detail in the Configuring Basic Repository Integrations document. As an example, here is the pull request to add the CCM for Alibaba Cloud to the OpenShift Prow. It configures the Tide mechanics as well as a pre-submit job to check the Go language formatting and a post-submit job to build the container images. openshift/release #19947","title":"Configure basic repository integrations"},{"location":"cloud-controller-manager/#integrating-with-other-openshift-components","text":"In OpenShift there are several operators which work together to ensure that the CCM is properly configured and also that new nodes which join the cluster are similarly configured for the infrastructure provider. To ensure that the new CCM and provider are properly recognized by all components there are several repositories which must be modified.","title":"Integrating with other OpenShift components"},{"location":"cloud-controller-manager/#openshiftapi","text":"Before progressing with the OpenShift integrations, the new infrastructure provider will need to be present in the OpenShift API as part of the infrastructure.config.openshift.io definition. TODO: add link to installer doc step that describes updating openshift/api","title":"openshift/api"},{"location":"cloud-controller-manager/#openshiftlibrary-go","text":"In order for the new infrastructure provider to be recognized by the Cluster Cloud Controller Manager Operator, and other operators, the OpenShift library-go project must be updated so that the IsCloudProviderExternal function returns the proper response. As an example, here is the pull request to update the IsCloudProviderExternal function to add support for IBM Cloud. openshift/library-go #1161 It is important to note that any changes to library-go must be vendored into the projects which are dependent upon library-go. This process can often involve several repositories that must be updated before all the components will work together. To make tracking these changes easier, an issue can be used to monitor the individual changes. For example, this is an issue which tracked changes for the GCP and vSphere updates: openshift/cluster-cloud-controller-manager-operator #135","title":"openshift/library-go"},{"location":"cloud-controller-manager/#openshiftcluster-cloud-controller-manager-operator","text":"OpenShift uses the Cluster Cloud Controller Manager Operator (CCCMO) to manage the deployment and maintenance of the CCMs. This operator will deploy the individual containers of the CCM and ensure their health and continued operation during the cluster lifecycle. Adding a new infrastructure provider will require creating a package within the CCCMO that will contain the code for deploying the new components as well as the templated manifests for them. For a deeper discussion of integrating with the CCCMO, please see the developer documenation from that repository. As an example, here are two pull requests that added the IBM Cloud CCM to the CCCMO. The first pull request adds the primary code changes and manifests for deployment. The second pull request adds the CCM image references for the CCCMO to utilize when deploying from an OpenShift release payload. openshift/cluster-cloud-controller-manager-operator #97 openshift/cluster-cloud-controller-manager-operator #105","title":"openshift/cluster-cloud-controller-manager-operator"},{"location":"component-infrastructure/","text":"Component Infrastructure Some components are not strictly required for an OpenShift installation, but their integration will improve user's experiences when operating OpenShift on an infrastructure provider. Image Registry OpenShift contains a component named the Image Registry Operator which is responsible for managing a singleton instance of the OpenShift registry. This operator will manage a container image registry for the OpenShift cluster which will provide persistent storage for ImageStreams, built images (from Builds and BuildConfigs), and intermediate images produced during build processes. By default, the operator will deploy an image registry that is supported by local, ephemeral, storage. This means that if the node containing the registy is rebooted, then the cached images will be lost. This configuration is not supported by Red Hat and is only added as default on new platforms to aid with building the platform. It must be changed before the new platform will be considered complete for general availability. Infrastructure providers can improve performance for their users by integrating an infrastructure specific storage configuration for the image registry operator. With proper integration to a storage service, images will be available in a persistent local storage. If the new infrastructure platform will not provide the storage for the image registry, then this component must be removed by default. For more information on how the image registry operator works, including instructions for development, please see the project documentation . For more information on how the integrated registry works in OpenShift, please see the OpenShift product documentation . To see examples of previous infrastructure integrations with the image registry operator, please see the follow pull requests: Support AlibabaCloud OSS for Image Registry Support IBmCloud and add IBM COS Storage Driver","title":"Component Infrastructure"},{"location":"component-infrastructure/#component-infrastructure","text":"Some components are not strictly required for an OpenShift installation, but their integration will improve user's experiences when operating OpenShift on an infrastructure provider.","title":"Component Infrastructure"},{"location":"component-infrastructure/#image-registry","text":"OpenShift contains a component named the Image Registry Operator which is responsible for managing a singleton instance of the OpenShift registry. This operator will manage a container image registry for the OpenShift cluster which will provide persistent storage for ImageStreams, built images (from Builds and BuildConfigs), and intermediate images produced during build processes. By default, the operator will deploy an image registry that is supported by local, ephemeral, storage. This means that if the node containing the registy is rebooted, then the cached images will be lost. This configuration is not supported by Red Hat and is only added as default on new platforms to aid with building the platform. It must be changed before the new platform will be considered complete for general availability. Infrastructure providers can improve performance for their users by integrating an infrastructure specific storage configuration for the image registry operator. With proper integration to a storage service, images will be available in a persistent local storage. If the new infrastructure platform will not provide the storage for the image registry, then this component must be removed by default. For more information on how the image registry operator works, including instructions for development, please see the project documentation . For more information on how the integrated registry works in OpenShift, please see the OpenShift product documentation . To see examples of previous infrastructure integrations with the image registry operator, please see the follow pull requests: Support AlibabaCloud OSS for Image Registry Support IBmCloud and add IBM COS Storage Driver","title":"Image Registry"},{"location":"container-storage-interface-driver/","text":"Container Storage Interface Driver Goal In the end, OpenShift installation should provide a cluster that is usable out of the box. Users can create PVCs or StatefulSets and get a decent storage for them. Install one CSI driver, the most useful for the platform. Usually it\u2019s one that provides block volumes (AWS EBS, GCP PD, Azure Disk, OpenStack Cinder, ...). Provide one default StorageClass that is good for a generic usage. Not too expensive, but not too slow either. Each cluster is different, don\u2019t anticipate application needs, leave creation of additional StorageClasses to the cluster administrators. They know better what they need. If the platform provides more storage backends, provide CSI drivers for them via OLM. This is out of scope of this guide, but library-go can be used for it too, see AWS EFS CSI driver operator . It even supports un-installation of the CSI driver. Overview Installation workflow Using GCP cloud and its Persistent Disk (PD) CSI driver as an example, but it works exactly the same on other platforms. During cluster installation, following things happen: cluster-version-operator (CVO) starts cluster-storage-operator (CSO) in namespace openshift-cluster-storage-operator . CVO does it by blindly applying YAML files in manifest/ directory of the operator image. Notice that manifests in cluster-storage-operator image will have the correct references to all images of all CSI drivers, CSI driver operators, CSI sidecars and so on. We have an automation that replaces the image names from quay.io/openshift to registry.redhat.io during release build. The operator gets them as env. variables. cluster-storage-operator sees that it runs on platform GCP and starts the GCP PD CSI driver operator in namespace openshift-cluster-csi-drivers and creates ClusterCSIDriver CR for it. cluster-storage-operator passes the correct images that the CSI driver operator should use as env. variables of the operator Deployment . GCP PD CSI driver operator observes its ClusterCSIDriver CR and installs GCP PD CSI driver. The operator reports the status of the installation to the ClusterCSIDriver CR status. GCP PD CSI driver operator gets all images that it should use for the driver + sidecars as env. vars. cluster-storage-operator observes ClusterCSIDriver CR status and reports its status to cluster-version-operator using ClusterOperator CR. cluster-version-operator reports installation/upgrade status to ClusterVersion CR. Upgrade Upgrade works in exactly the same way as installation, except that cluster-storage-operator , CSI driver operator and the CSI driver are updated, i.e. their Deployment / DaemonSets are updated instead of created. Updated image names are propagated exactly as during the installation - as env. variables from CVO through CSO to CSI driver operator(s). Cluster Un-installation Nothing is needed from the driver or its operator during cluster un-installation. However, openshift-install destroy cluster itself should destroy all volumes that were dynamically provisioned in the cluster. In other words: The CSI driver must tag / label all volumes created during the cluster lifetime with the cluster ID. Most CSI drivers have a special argument to add tags to all created volumes. Their CSI driver operator can file it easily. See GCP PD CSI driver operator that sets tag (=label in GCP jargon) kubernetes-io-cluster-${CLUSTER_ID}=owned . openshift-install destroy cluster must list all volumes that are tagged with the cluster ID and delete them. See code for GCP PD . ClusterCSIDriver ClusterCSIDriver is a Custom Resource . Its CRD is created during cluster installation. Each CSI driver operator uses its own dedicated CR name. For example, GCP PD CSI driver operator uses ClusterCSIDriver instance named pd.csi.storage.gke.io . See openshift/api repository for details about the available fields in the CR and for allowed CSI drivers. The ClusterCSIDriver is heavily based on ClusterOperator CR - it has the same Spec and Status . ClusterCSIDriver does not provide any configuration of the operator nor the driver except for log level, both of the operator and its operand (=the CSI driver). A CSI driver operator should install the CSI driver with some default parameters that suit the best in OpenShift. If the operator needs it, it can get parameters from install-config or other OCP components by getting corresponding API objects - most of the cluster is up and running at the time CSI driver operator starts. Using ClusterCSIDriver.Status the CSI driver operator reports status of the CSI driver \"up the chain\", to cluster-storage-operator . Especially see ClusterCSIDriver.Status.Conditions , they're directly transferred by cluster-storage-operator to overall status of storage in ClusterOperator CR. openshift/library-go openshift/library-go is a collection of functions that allow us to build OpenShift operators easily. Most of the functionality of a CSI driver operator is already available there. In the ideal case, a CSI driver operator just provides yaml files of the CSI driver ( Deployment , DaemonSet , ServiceAccount , Role , ClusterRole , RoleBindings , ClusterRoleBindings , ...) and initializes + starts library-go Controllers that handle the rest. There is already a lot of internal OpenShift knowledge in these controllers, for example: * Inject cluster-wide HTTP proxy to driver pods. * Inject custom CA bundles to the driver pods. * Put the controller Pods to the master nodes (if they\u2019re available). * Scale down nr. of controller Pods on single-node cluster. * Configure leader-election of the CSI sidecar appropriately for the platform. * (Optionally) restart CSI driver pods when cloud credentials change, so the CSI driver does not need to reload the credentials on its own. * Replace image name placeholders with the current images for an OCP release. * Propagate log level changes. * Create a default storage class. * \"Stomp\" over any user changes in the driver Deployment / DaemonSets - the operator knows better how to run the CSI driver. * Report its status correctly via ClusterCSIDriver.Status.Conditions . * Etc. CSI sidecars OpenShift already ships CSI sidecars, usually with the version that corresponds to the Kubernetes version in each OCP release. These sidecars MUST be used by the CSI driver. A CSI driver operator gets their image names (SHAs) as env. variables. Credentials The CSI driver should be able to consume Secrets provided by the cloud-credentials-operator (CCO). Technically it\u2019s possible that a CSI driver operator translates the Secrets from CCO to a format understood by the CSI driver, but you save some sweat and tears if you avoid doing so. CredentialsRequest for the CSI driver must be present in cluster-storage-operator manifests/ directory , to be available during cluster installation and/or extraction of CredentialRequests during installation. Metrics In OpenShift, we provide metrics through HTTPS. Since most CSI driver and all CSI sidecars expose metrics as HTTP endpoints, we add kube-rbac-proxy containers to the driver Pods. They provide a proxy that listens on Pod's public IP address and proxy HTTPS requests from Prometheus to HTTP metric endpoints of the driver / sidecar. The HTTP endpoint is available only on loopback and it's not exposed outside of the driver Pod. If possible, make the CSI driver working without metrics and add them later. They\u2019re tricky to set up correctly. In general, follow GCP PD CSI driver operator example how the metric ports are exposed in the Pods and how their scraping is configured in ServiceMonitor CR . OpenShift shall handle TLS side of things, i.e. it will provide a Secret with TLS key that can be used in kube-rbac-proxy sidecars using Secret volumes . CI If you do not do so yet, test your CSI driver in vanilla Kubernetes frequently using Kubernetes storage tests . Neither OpenShift or an operator is needed here and all your Kubernetes customers will benefit from it. OpenShift packages the same tests as openshift-test binary / container image . The binary just wraps the tests with proper OpenShift privileges, but otherwise they're the same tests as upstream and consume the same manifest.yaml file. To run the tests: Place manifest.yaml and kubeconfig in a single directory, e.g. data/ Run openshift-tests from quay.io/repository/openshift/origin-tests image: $ podman run -v `pwd`:/data:z --rm -it quay.io/repository/openshift/origin-tests:latest sh -c \"KUBECONFIG=/data/kubeconfig TEST_CSI_DRIVER_FILES=/data/manifest.yaml /usr/bin/openshift-tests run openshift/csi --junit-dir /data/results\" In the end, a CI job will run the same tests. CI for a CSI driver is tricky to set up and probably should be done by Red Hat. Deliverables CSI driver Fork the CSI driver under github.com/openshift and integrate it with Prow and Tide as described elsewhere in this guide . Make sure that the CSI driver image is built in Red Hat's CI. openshift/api changes Add your CSI driver name to allowed ClusterCSIDriver names here and here . You must update cluster-storage-operator to the new openshift/api version to get the ClusterCSIDriver CRD updated during cluster installation / update. A simple go get -u github.com/openshift/api@master is enough. CSI driver operator The CSI driver must be installed via an operator and the operator must be based on library-go. As listed above, it has a lot of knowledge about OpenShift. You cannot use an operator previously developed in-house and using OLM! Ask your Red Hat representative to create a new empty repo in gihub.com/openshift . Take the GCP PD CSI driver operator as a base and copy it there. Replace traces of \"GCP PD\" and \"gcp-pd\" in the whole repo with your CSI driver name. If you're lucky, you may be done! The only useful code is in pkg/operator/starter.go and it basically only instantiates + starts CSI driver controllers from library-go. The most important thing is the assets/ directory . It contains YAML files of all objects that the CSI driver needs. Check ${} \"variables\" in the files there - the operator will replace e.g. ${LOG_LEVEL} with \"2\" , ${DRIVER_IMAGE} with the driver image name etc. Check kube-rbac-proxy containers and how they provide HTTPS endpoints for metrics of each CSI sidecar. CSI driver deployment As result, the operator must deploy the CSI driver this way: The CSI driver runs in namespace openshift-cluster-csi-drivers . OpenShift can be deployed by various tools and in different modes. The most typical mode is a cluster with 3 dedicated master and a number of worker nodes. In this mode a CSI driver runs as: Deployment with 2 replicas of CSI controler Pods (driver + external-provisioner, external-attacher, external-resizer, external snapshotter, livenessprobe and nr. of kube-rbac-proxies). These pods run on master nodes and have anti-affinity towards each other (i.e. run on different master nodes). DaemonSet that matches all nodes (incl. masters) with the driver + node-driver-registrar + livenessprobe. The DaemonSet has Rolling update strategy + tolerates 10% of missing pods (to be able to update 10% of pods at the same time, speeding up updates of large clusters). All containers (both in the DaemonSet and Deployment ) have CPU and memory requests filed In a single-node cluster, the Deployment with the controller pods has 1 replica. In a cluster without dedicated master nodes, the Deployment has no node selector. Most of the above is automatically configured and managed by our common library-go code! CI The operator repository must contain a yaml manifest for e2e tests in [ test/e2e directory] ((https://github.com/openshift/gcp-pd-csi-driver-operator/tree/master/test/e2e) and Dockerfile.test for it. In our CI we can distribute \"stuff\" like the test manifest only as a container images, hence we build a container with the manifest in CI. FROM: src will then use the same image as we built for the driver sources, as checked out from github. cluster-storage-operator Add CredentialsRequest for the CSI driver to `manifest/ directory of CSO](https://github.com/openshift/cluster-storage-operator/tree/master/manifests). Follow existing examples there. Add complete assets of the CSI driver operator to assets/csidriveroperators/<platform> . It must contain all RBACs that the operator needs (incl. those that the operator will grant to the driver and all CSI sidecars!), ServiceAccount and Deployment of the CSI driver operator. Check GCE PD as an example. Teach CSO how / when to start the CSI driver operator via a little glue code. Write Get<driver name>OperatorConfig() , that returns a structure describing how to start the operator. Replacement strings for ${OPERATOR_IMAGE} and ${DRIVER_IMAGE} in the operator Deployment. Platform , on which the operator should start. What static assets to create when the operator should run. Deployment asset. ClusterCSIDriver CR to create. Initialize list of supported CSI driver operators at the operator startup. CSO will then handle the rest - if the platform where OCP runs corresponds to the platform that the CSI driver operator declared, CSO will start the operator + ClusterCSIDriver CR. CSI driver operator deployment CSO must deploy the CSI driver operator as a Deployment with 1 replica that runs on the master nodes, if they\u2019re available. Development It\u2019s possible to start the CSI driver operator on the command line, see GCP PD example . It\u2019s possible to start the cluster-storage-operator on the command line. It's currently not documented, but provide expected env. variables + start the operator in the same way as the GCP PD CSI driver operator above. Troubleshooting Both the driver + CSI driver operator API objects and logs will be available in must-gather collected by oc adm must-gater out of the box, no need to configure anything. CSO CSO reports its status in ClusterOperator CR oc get clusteroperator storage oc get clusteroperator storage -o yaml In addition, CSO reports more detailed status in Storage CR oc get storage -o yaml Especially check its conditions. You can bump CSO log level in the Storage CR oc edit storage Note that the logLevel does not propagate to CSI driver operators! You can \"pause\" the operator by setting managementLevel: Unmanaged . For example to test manual changes to the CSI driver operator Deployment . Otherwise, the operator will overwrite any of your changes. CSI driver operator The driver operator reports its status in ClusterCSIDriver CR oc get clustercsidriver -o yaml You can bump CSO log level in the ClusterCSIDriver CR oc edit clustercsidriver Note that logLevel does propagate to the CSI driver! You can \"pause\" the operator by setting managementLevel: Unmanaged . For example to test manual changes to the driver Deployment / DaemonSet . Otherwise, the operator will overwrite any of your changes.","title":"Container Storage Interface Driver"},{"location":"container-storage-interface-driver/#container-storage-interface-driver","text":"","title":"Container Storage Interface Driver"},{"location":"container-storage-interface-driver/#goal","text":"In the end, OpenShift installation should provide a cluster that is usable out of the box. Users can create PVCs or StatefulSets and get a decent storage for them. Install one CSI driver, the most useful for the platform. Usually it\u2019s one that provides block volumes (AWS EBS, GCP PD, Azure Disk, OpenStack Cinder, ...). Provide one default StorageClass that is good for a generic usage. Not too expensive, but not too slow either. Each cluster is different, don\u2019t anticipate application needs, leave creation of additional StorageClasses to the cluster administrators. They know better what they need. If the platform provides more storage backends, provide CSI drivers for them via OLM. This is out of scope of this guide, but library-go can be used for it too, see AWS EFS CSI driver operator . It even supports un-installation of the CSI driver.","title":"Goal"},{"location":"container-storage-interface-driver/#overview","text":"","title":"Overview"},{"location":"container-storage-interface-driver/#installation-workflow","text":"Using GCP cloud and its Persistent Disk (PD) CSI driver as an example, but it works exactly the same on other platforms. During cluster installation, following things happen: cluster-version-operator (CVO) starts cluster-storage-operator (CSO) in namespace openshift-cluster-storage-operator . CVO does it by blindly applying YAML files in manifest/ directory of the operator image. Notice that manifests in cluster-storage-operator image will have the correct references to all images of all CSI drivers, CSI driver operators, CSI sidecars and so on. We have an automation that replaces the image names from quay.io/openshift to registry.redhat.io during release build. The operator gets them as env. variables. cluster-storage-operator sees that it runs on platform GCP and starts the GCP PD CSI driver operator in namespace openshift-cluster-csi-drivers and creates ClusterCSIDriver CR for it. cluster-storage-operator passes the correct images that the CSI driver operator should use as env. variables of the operator Deployment . GCP PD CSI driver operator observes its ClusterCSIDriver CR and installs GCP PD CSI driver. The operator reports the status of the installation to the ClusterCSIDriver CR status. GCP PD CSI driver operator gets all images that it should use for the driver + sidecars as env. vars. cluster-storage-operator observes ClusterCSIDriver CR status and reports its status to cluster-version-operator using ClusterOperator CR. cluster-version-operator reports installation/upgrade status to ClusterVersion CR.","title":"Installation workflow"},{"location":"container-storage-interface-driver/#upgrade","text":"Upgrade works in exactly the same way as installation, except that cluster-storage-operator , CSI driver operator and the CSI driver are updated, i.e. their Deployment / DaemonSets are updated instead of created. Updated image names are propagated exactly as during the installation - as env. variables from CVO through CSO to CSI driver operator(s).","title":"Upgrade"},{"location":"container-storage-interface-driver/#cluster-un-installation","text":"Nothing is needed from the driver or its operator during cluster un-installation. However, openshift-install destroy cluster itself should destroy all volumes that were dynamically provisioned in the cluster. In other words: The CSI driver must tag / label all volumes created during the cluster lifetime with the cluster ID. Most CSI drivers have a special argument to add tags to all created volumes. Their CSI driver operator can file it easily. See GCP PD CSI driver operator that sets tag (=label in GCP jargon) kubernetes-io-cluster-${CLUSTER_ID}=owned . openshift-install destroy cluster must list all volumes that are tagged with the cluster ID and delete them. See code for GCP PD .","title":"Cluster Un-installation"},{"location":"container-storage-interface-driver/#clustercsidriver","text":"ClusterCSIDriver is a Custom Resource . Its CRD is created during cluster installation. Each CSI driver operator uses its own dedicated CR name. For example, GCP PD CSI driver operator uses ClusterCSIDriver instance named pd.csi.storage.gke.io . See openshift/api repository for details about the available fields in the CR and for allowed CSI drivers. The ClusterCSIDriver is heavily based on ClusterOperator CR - it has the same Spec and Status . ClusterCSIDriver does not provide any configuration of the operator nor the driver except for log level, both of the operator and its operand (=the CSI driver). A CSI driver operator should install the CSI driver with some default parameters that suit the best in OpenShift. If the operator needs it, it can get parameters from install-config or other OCP components by getting corresponding API objects - most of the cluster is up and running at the time CSI driver operator starts. Using ClusterCSIDriver.Status the CSI driver operator reports status of the CSI driver \"up the chain\", to cluster-storage-operator . Especially see ClusterCSIDriver.Status.Conditions , they're directly transferred by cluster-storage-operator to overall status of storage in ClusterOperator CR.","title":"ClusterCSIDriver"},{"location":"container-storage-interface-driver/#openshiftlibrary-go","text":"openshift/library-go is a collection of functions that allow us to build OpenShift operators easily. Most of the functionality of a CSI driver operator is already available there. In the ideal case, a CSI driver operator just provides yaml files of the CSI driver ( Deployment , DaemonSet , ServiceAccount , Role , ClusterRole , RoleBindings , ClusterRoleBindings , ...) and initializes + starts library-go Controllers that handle the rest. There is already a lot of internal OpenShift knowledge in these controllers, for example: * Inject cluster-wide HTTP proxy to driver pods. * Inject custom CA bundles to the driver pods. * Put the controller Pods to the master nodes (if they\u2019re available). * Scale down nr. of controller Pods on single-node cluster. * Configure leader-election of the CSI sidecar appropriately for the platform. * (Optionally) restart CSI driver pods when cloud credentials change, so the CSI driver does not need to reload the credentials on its own. * Replace image name placeholders with the current images for an OCP release. * Propagate log level changes. * Create a default storage class. * \"Stomp\" over any user changes in the driver Deployment / DaemonSets - the operator knows better how to run the CSI driver. * Report its status correctly via ClusterCSIDriver.Status.Conditions . * Etc.","title":"openshift/library-go"},{"location":"container-storage-interface-driver/#csi-sidecars","text":"OpenShift already ships CSI sidecars, usually with the version that corresponds to the Kubernetes version in each OCP release. These sidecars MUST be used by the CSI driver. A CSI driver operator gets their image names (SHAs) as env. variables.","title":"CSI sidecars"},{"location":"container-storage-interface-driver/#credentials","text":"The CSI driver should be able to consume Secrets provided by the cloud-credentials-operator (CCO). Technically it\u2019s possible that a CSI driver operator translates the Secrets from CCO to a format understood by the CSI driver, but you save some sweat and tears if you avoid doing so. CredentialsRequest for the CSI driver must be present in cluster-storage-operator manifests/ directory , to be available during cluster installation and/or extraction of CredentialRequests during installation.","title":"Credentials"},{"location":"container-storage-interface-driver/#metrics","text":"In OpenShift, we provide metrics through HTTPS. Since most CSI driver and all CSI sidecars expose metrics as HTTP endpoints, we add kube-rbac-proxy containers to the driver Pods. They provide a proxy that listens on Pod's public IP address and proxy HTTPS requests from Prometheus to HTTP metric endpoints of the driver / sidecar. The HTTP endpoint is available only on loopback and it's not exposed outside of the driver Pod. If possible, make the CSI driver working without metrics and add them later. They\u2019re tricky to set up correctly. In general, follow GCP PD CSI driver operator example how the metric ports are exposed in the Pods and how their scraping is configured in ServiceMonitor CR . OpenShift shall handle TLS side of things, i.e. it will provide a Secret with TLS key that can be used in kube-rbac-proxy sidecars using Secret volumes .","title":"Metrics"},{"location":"container-storage-interface-driver/#ci","text":"If you do not do so yet, test your CSI driver in vanilla Kubernetes frequently using Kubernetes storage tests . Neither OpenShift or an operator is needed here and all your Kubernetes customers will benefit from it. OpenShift packages the same tests as openshift-test binary / container image . The binary just wraps the tests with proper OpenShift privileges, but otherwise they're the same tests as upstream and consume the same manifest.yaml file. To run the tests: Place manifest.yaml and kubeconfig in a single directory, e.g. data/ Run openshift-tests from quay.io/repository/openshift/origin-tests image: $ podman run -v `pwd`:/data:z --rm -it quay.io/repository/openshift/origin-tests:latest sh -c \"KUBECONFIG=/data/kubeconfig TEST_CSI_DRIVER_FILES=/data/manifest.yaml /usr/bin/openshift-tests run openshift/csi --junit-dir /data/results\" In the end, a CI job will run the same tests. CI for a CSI driver is tricky to set up and probably should be done by Red Hat.","title":"CI"},{"location":"container-storage-interface-driver/#deliverables","text":"","title":"Deliverables"},{"location":"container-storage-interface-driver/#csi-driver","text":"Fork the CSI driver under github.com/openshift and integrate it with Prow and Tide as described elsewhere in this guide . Make sure that the CSI driver image is built in Red Hat's CI.","title":"CSI driver"},{"location":"container-storage-interface-driver/#openshiftapi-changes","text":"Add your CSI driver name to allowed ClusterCSIDriver names here and here . You must update cluster-storage-operator to the new openshift/api version to get the ClusterCSIDriver CRD updated during cluster installation / update. A simple go get -u github.com/openshift/api@master is enough.","title":"openshift/api changes"},{"location":"container-storage-interface-driver/#csi-driver-operator","text":"The CSI driver must be installed via an operator and the operator must be based on library-go. As listed above, it has a lot of knowledge about OpenShift. You cannot use an operator previously developed in-house and using OLM! Ask your Red Hat representative to create a new empty repo in gihub.com/openshift . Take the GCP PD CSI driver operator as a base and copy it there. Replace traces of \"GCP PD\" and \"gcp-pd\" in the whole repo with your CSI driver name. If you're lucky, you may be done! The only useful code is in pkg/operator/starter.go and it basically only instantiates + starts CSI driver controllers from library-go. The most important thing is the assets/ directory . It contains YAML files of all objects that the CSI driver needs. Check ${} \"variables\" in the files there - the operator will replace e.g. ${LOG_LEVEL} with \"2\" , ${DRIVER_IMAGE} with the driver image name etc. Check kube-rbac-proxy containers and how they provide HTTPS endpoints for metrics of each CSI sidecar.","title":"CSI driver operator"},{"location":"container-storage-interface-driver/#csi-driver-deployment","text":"As result, the operator must deploy the CSI driver this way: The CSI driver runs in namespace openshift-cluster-csi-drivers . OpenShift can be deployed by various tools and in different modes. The most typical mode is a cluster with 3 dedicated master and a number of worker nodes. In this mode a CSI driver runs as: Deployment with 2 replicas of CSI controler Pods (driver + external-provisioner, external-attacher, external-resizer, external snapshotter, livenessprobe and nr. of kube-rbac-proxies). These pods run on master nodes and have anti-affinity towards each other (i.e. run on different master nodes). DaemonSet that matches all nodes (incl. masters) with the driver + node-driver-registrar + livenessprobe. The DaemonSet has Rolling update strategy + tolerates 10% of missing pods (to be able to update 10% of pods at the same time, speeding up updates of large clusters). All containers (both in the DaemonSet and Deployment ) have CPU and memory requests filed In a single-node cluster, the Deployment with the controller pods has 1 replica. In a cluster without dedicated master nodes, the Deployment has no node selector. Most of the above is automatically configured and managed by our common library-go code!","title":"CSI driver deployment"},{"location":"container-storage-interface-driver/#ci_1","text":"The operator repository must contain a yaml manifest for e2e tests in [ test/e2e directory] ((https://github.com/openshift/gcp-pd-csi-driver-operator/tree/master/test/e2e) and Dockerfile.test for it. In our CI we can distribute \"stuff\" like the test manifest only as a container images, hence we build a container with the manifest in CI. FROM: src will then use the same image as we built for the driver sources, as checked out from github.","title":"CI"},{"location":"container-storage-interface-driver/#cluster-storage-operator","text":"Add CredentialsRequest for the CSI driver to `manifest/ directory of CSO](https://github.com/openshift/cluster-storage-operator/tree/master/manifests). Follow existing examples there. Add complete assets of the CSI driver operator to assets/csidriveroperators/<platform> . It must contain all RBACs that the operator needs (incl. those that the operator will grant to the driver and all CSI sidecars!), ServiceAccount and Deployment of the CSI driver operator. Check GCE PD as an example. Teach CSO how / when to start the CSI driver operator via a little glue code. Write Get<driver name>OperatorConfig() , that returns a structure describing how to start the operator. Replacement strings for ${OPERATOR_IMAGE} and ${DRIVER_IMAGE} in the operator Deployment. Platform , on which the operator should start. What static assets to create when the operator should run. Deployment asset. ClusterCSIDriver CR to create. Initialize list of supported CSI driver operators at the operator startup. CSO will then handle the rest - if the platform where OCP runs corresponds to the platform that the CSI driver operator declared, CSO will start the operator + ClusterCSIDriver CR.","title":"cluster-storage-operator"},{"location":"container-storage-interface-driver/#csi-driver-operator-deployment","text":"CSO must deploy the CSI driver operator as a Deployment with 1 replica that runs on the master nodes, if they\u2019re available.","title":"CSI driver operator deployment"},{"location":"container-storage-interface-driver/#development","text":"It\u2019s possible to start the CSI driver operator on the command line, see GCP PD example . It\u2019s possible to start the cluster-storage-operator on the command line. It's currently not documented, but provide expected env. variables + start the operator in the same way as the GCP PD CSI driver operator above.","title":"Development"},{"location":"container-storage-interface-driver/#troubleshooting","text":"Both the driver + CSI driver operator API objects and logs will be available in must-gather collected by oc adm must-gater out of the box, no need to configure anything.","title":"Troubleshooting"},{"location":"container-storage-interface-driver/#cso","text":"CSO reports its status in ClusterOperator CR oc get clusteroperator storage oc get clusteroperator storage -o yaml In addition, CSO reports more detailed status in Storage CR oc get storage -o yaml Especially check its conditions. You can bump CSO log level in the Storage CR oc edit storage Note that the logLevel does not propagate to CSI driver operators! You can \"pause\" the operator by setting managementLevel: Unmanaged . For example to test manual changes to the CSI driver operator Deployment . Otherwise, the operator will overwrite any of your changes.","title":"CSO"},{"location":"container-storage-interface-driver/#csi-driver-operator_1","text":"The driver operator reports its status in ClusterCSIDriver CR oc get clustercsidriver -o yaml You can bump CSO log level in the ClusterCSIDriver CR oc edit clustercsidriver Note that logLevel does propagate to the CSI driver! You can \"pause\" the operator by setting managementLevel: Unmanaged . For example to test manual changes to the driver Deployment / DaemonSet . Otherwise, the operator will overwrite any of your changes.","title":"CSI driver operator"},{"location":"continuous-integration-and-testing/","text":"Continuous Integration and Testing Continuous Integration (CI) testing for OpenShift and its supported infrastructure providers is handled through Prow; the same system used for the Kubernetes project. The landing page for OpenShift's CI can be found here , but we'll add some context for you as a newly supported OpenShift infrastructure provider. Some of the CI components will be hosted by you and some hosted by Red Hat. We'll start by looking at what you should have. Your Infrastructure You, as the infrastructure provider, will supply infrastructure where test OpenShift clusters will be installed and end-to-end (e2e) tests will be executed. The requirements vary from provider to provider. For example, VMWare and AWS are hosted very differently (on-premise vs hosted) so each one has caveats. But, there are some common requirements. API endpoint[s] for your service. i.e. What does your CLI or terraform communicate with to provision infrastructure? User accounts with required permissions for OpenShift installation. i.e. Can you share credentials that Red Hat can use to provision in your infrastructure? Ability to run multiple OpenShift clusters. i.e. Do you have enough resources to run multiple OpenShift clusters? More on this below. Network infrastructure including: DHCP Load balancing (Layer 4) Gateways and/or bastions for possible user access Sufficient storage for multiple OpenShift clusters. It is important to note that you will need to be able to run multiple OpenShift clusters at a time on your infrastructure. Why? Each code change related to your infrastructure provider will need to run unit and e2e tests. The e2e tests require an isolated OpenShift cluster so tests can run without interference. Its very likely to have more than one code change in flight at a time so having the ability to run multiple OpenShift clusters is necessary to quickly provide the test results to the engineers. In order to calculate your infrastructure size and costs, use this OpenShift Minimum Hardware Requirements document. Red Hat's Infrastructure Red Hat will host a cluster where Prow Jobs are run. These Prow Jobs will execute many steps which include infrastructure setup, provisioning a cluster on your infrastructure, running tests, and deprovisioning. The steps are a part of a chain and workflow (see here ). This Red Hat hosted cluster will need to be able to communicate with you so that it can run these steps, so some account and networking setup may be necessary. Connecting with OpenShift CI In each of the sections below, the outbound links contain examples of the code changes and pull requests. Create Cluster Profile Creating your Cluster Profile for OpenShift's CI is a major stepping stone to running CI jobs. Details on how to do this can be found here: https://docs.ci.openshift.org/docs/how-tos/adding-a-cluster-profile/. Red Hat will work with you to complete each of the steps since they will require review and code merges into the OpenShift CI system. Note that in the Providing Credentials step, you should work with Red Hat on how to access the Vault used for OpenShift CI. Adding to CI Step Registry OpenShift CI jobs are composed of multiple workflows and steps. You will need to add these to complete the integration with OpenShift CI. Documentation on creating workflows and steps can be found here . The registry of steps can be found here . Finally, an auto-generated document of all existing workflows, chains, and steps can be found here and is a great reference. Make sure that you have steps for each method of installation. For example, CI steps for UPI, IPI, disconnected network installations, or any other types.","title":"Continuous Integration"},{"location":"continuous-integration-and-testing/#continuous-integration-and-testing","text":"Continuous Integration (CI) testing for OpenShift and its supported infrastructure providers is handled through Prow; the same system used for the Kubernetes project. The landing page for OpenShift's CI can be found here , but we'll add some context for you as a newly supported OpenShift infrastructure provider. Some of the CI components will be hosted by you and some hosted by Red Hat. We'll start by looking at what you should have.","title":"Continuous Integration and Testing"},{"location":"continuous-integration-and-testing/#your-infrastructure","text":"You, as the infrastructure provider, will supply infrastructure where test OpenShift clusters will be installed and end-to-end (e2e) tests will be executed. The requirements vary from provider to provider. For example, VMWare and AWS are hosted very differently (on-premise vs hosted) so each one has caveats. But, there are some common requirements. API endpoint[s] for your service. i.e. What does your CLI or terraform communicate with to provision infrastructure? User accounts with required permissions for OpenShift installation. i.e. Can you share credentials that Red Hat can use to provision in your infrastructure? Ability to run multiple OpenShift clusters. i.e. Do you have enough resources to run multiple OpenShift clusters? More on this below. Network infrastructure including: DHCP Load balancing (Layer 4) Gateways and/or bastions for possible user access Sufficient storage for multiple OpenShift clusters. It is important to note that you will need to be able to run multiple OpenShift clusters at a time on your infrastructure. Why? Each code change related to your infrastructure provider will need to run unit and e2e tests. The e2e tests require an isolated OpenShift cluster so tests can run without interference. Its very likely to have more than one code change in flight at a time so having the ability to run multiple OpenShift clusters is necessary to quickly provide the test results to the engineers. In order to calculate your infrastructure size and costs, use this OpenShift Minimum Hardware Requirements document.","title":"Your Infrastructure"},{"location":"continuous-integration-and-testing/#red-hats-infrastructure","text":"Red Hat will host a cluster where Prow Jobs are run. These Prow Jobs will execute many steps which include infrastructure setup, provisioning a cluster on your infrastructure, running tests, and deprovisioning. The steps are a part of a chain and workflow (see here ). This Red Hat hosted cluster will need to be able to communicate with you so that it can run these steps, so some account and networking setup may be necessary.","title":"Red Hat's Infrastructure"},{"location":"continuous-integration-and-testing/#connecting-with-openshift-ci","text":"In each of the sections below, the outbound links contain examples of the code changes and pull requests.","title":"Connecting with OpenShift CI"},{"location":"continuous-integration-and-testing/#create-cluster-profile","text":"Creating your Cluster Profile for OpenShift's CI is a major stepping stone to running CI jobs. Details on how to do this can be found here: https://docs.ci.openshift.org/docs/how-tos/adding-a-cluster-profile/. Red Hat will work with you to complete each of the steps since they will require review and code merges into the OpenShift CI system. Note that in the Providing Credentials step, you should work with Red Hat on how to access the Vault used for OpenShift CI.","title":"Create Cluster Profile"},{"location":"continuous-integration-and-testing/#adding-to-ci-step-registry","text":"OpenShift CI jobs are composed of multiple workflows and steps. You will need to add these to complete the integration with OpenShift CI. Documentation on creating workflows and steps can be found here . The registry of steps can be found here . Finally, an auto-generated document of all existing workflows, chains, and steps can be found here and is a great reference. Make sure that you have steps for each method of installation. For example, CI steps for UPI, IPI, disconnected network installations, or any other types.","title":"Adding to CI Step Registry"},{"location":"documentation/","text":"Documentation All OpenShift components that are released from Red Hat will have accompanying documentation in the OpenShift product documentation . The content for these product documents are created and maintained by Red Hat, but they are inspired by the OpenShift enhancement , repository level documentation, and direct discussions with the component engineers. Repository level documentation Any component that has its code in a Git repository must have documentation in that repository to cover its usage and troubleshooting. This repository level documentation forms the basis of the product documentation and also helps OpenShift users to have a deeper understanding the software they are deploying and running. This documentation should be written by the authors of the software component. Examples of Respository Level Documentation Machine API Operator, the documenation directory contains several documents structured by intended audience and topic. Alibaba Machine API Actuator, the README file contains detailed information about deployment and usage. Product level documentation As mentioned above, all components in OpenShift will have product documentation created by Red Hat content teams. This documentation is inspired by the repository level content, and direct communication with the engineers who are creating and maintaining the software. During the development of new infrastructure components it is expected that Red Hat content writers will have access to the repository level documentation and to the original authors of the components in question.","title":"Documentation"},{"location":"documentation/#documentation","text":"All OpenShift components that are released from Red Hat will have accompanying documentation in the OpenShift product documentation . The content for these product documents are created and maintained by Red Hat, but they are inspired by the OpenShift enhancement , repository level documentation, and direct discussions with the component engineers.","title":"Documentation"},{"location":"documentation/#repository-level-documentation","text":"Any component that has its code in a Git repository must have documentation in that repository to cover its usage and troubleshooting. This repository level documentation forms the basis of the product documentation and also helps OpenShift users to have a deeper understanding the software they are deploying and running. This documentation should be written by the authors of the software component. Examples of Respository Level Documentation Machine API Operator, the documenation directory contains several documents structured by intended audience and topic. Alibaba Machine API Actuator, the README file contains detailed information about deployment and usage.","title":"Repository level documentation"},{"location":"documentation/#product-level-documentation","text":"As mentioned above, all components in OpenShift will have product documentation created by Red Hat content teams. This documentation is inspired by the repository level content, and direct communication with the engineers who are creating and maintaining the software. During the development of new infrastructure components it is expected that Red Hat content writers will have access to the repository level documentation and to the original authors of the components in question.","title":"Product level documentation"},{"location":"information-gathering/","text":"Information Gathering The following items will be needed to move forward smoothly in the onboarding process. Use the questions below to build an inventory of your existing capabilities or gaps. Red Hat will review these to help estimate the amount of work. Compute Do you have a list and documentation of pre-configured instance types (e.g. m4.2xlarge ) or are machines configured another way? What are the supported processor architectures and what do you wish to use with OpenShift? Do you have multiple instance types (e.g. compute, graphics, HPC, etc)? Can you organize machines into zones, regions, or other types of groups? Additionally, as a reference, you can review the minimum hardware requirements for OpenShift. Storage What types of storage do you offer (e.g. block, object, filesystem, fast, budget, etc)? Do you have any storage performance benchmarks you can share? Do you support features like snapshots and disk expansion? Networking Do you have a native load balancing solution? If so, does it meet the requirements for OpenShift ? Do you have a IP Address Management solution? (e.g. DHCP and DNS)? Do you support static IP assignment via DHCP? Will you be able to support each of the DNS record types used by OpenShift ? Do you have features like VPC, subnets, and firewalls? Do you have disconnected, offline, or restricted network capabilities? Security Do you have an IDM or Authentication solution? If so, what standard does it follow (e.g. OAuth, OpenID, etc)? Does you have role based access controls (RBAC) available or another authorization solution? Do you have hardware security module (HSM) support? Development and Community Do you have API documentation and libraries for your infrastructure? Are there code examples? Is there a metadata service for your infrastructure? (e.g. 169.254.169.254 ) Are there any existing Kubernetes interface implementations? For example: Container Storage Interface (CSI) Container Networking Interface (CNI) Cloud Controller Manager (CCM) Cluster API (CAPI) Provider The OpenShift installer relies on Terraform to provision resources. Do you have a Terraform provider? Do you have support for Fedora CoreOS , Ignition , and Afterburn ?","title":"Information Gathering"},{"location":"information-gathering/#information-gathering","text":"The following items will be needed to move forward smoothly in the onboarding process. Use the questions below to build an inventory of your existing capabilities or gaps. Red Hat will review these to help estimate the amount of work.","title":"Information Gathering"},{"location":"information-gathering/#compute","text":"Do you have a list and documentation of pre-configured instance types (e.g. m4.2xlarge ) or are machines configured another way? What are the supported processor architectures and what do you wish to use with OpenShift? Do you have multiple instance types (e.g. compute, graphics, HPC, etc)? Can you organize machines into zones, regions, or other types of groups? Additionally, as a reference, you can review the minimum hardware requirements for OpenShift.","title":"Compute"},{"location":"information-gathering/#storage","text":"What types of storage do you offer (e.g. block, object, filesystem, fast, budget, etc)? Do you have any storage performance benchmarks you can share? Do you support features like snapshots and disk expansion?","title":"Storage"},{"location":"information-gathering/#networking","text":"Do you have a native load balancing solution? If so, does it meet the requirements for OpenShift ? Do you have a IP Address Management solution? (e.g. DHCP and DNS)? Do you support static IP assignment via DHCP? Will you be able to support each of the DNS record types used by OpenShift ? Do you have features like VPC, subnets, and firewalls? Do you have disconnected, offline, or restricted network capabilities?","title":"Networking"},{"location":"information-gathering/#security","text":"Do you have an IDM or Authentication solution? If so, what standard does it follow (e.g. OAuth, OpenID, etc)? Does you have role based access controls (RBAC) available or another authorization solution? Do you have hardware security module (HSM) support?","title":"Security"},{"location":"information-gathering/#development-and-community","text":"Do you have API documentation and libraries for your infrastructure? Are there code examples? Is there a metadata service for your infrastructure? (e.g. 169.254.169.254 ) Are there any existing Kubernetes interface implementations? For example: Container Storage Interface (CSI) Container Networking Interface (CNI) Cloud Controller Manager (CCM) Cluster API (CAPI) Provider The OpenShift installer relies on Terraform to provision resources. Do you have a Terraform provider? Do you have support for Fedora CoreOS , Ignition , and Afterburn ?","title":"Development and Community"},{"location":"installer/","text":"Installer The OpenShift Installer repo contains the code for the openshift-install Go binary as well as templates and documentation for user-provisioned infrastructure. openshift-install provides a user interface for the installation process on multiple cloud platforms. Users provide install configuration through an install-config.yaml file, which can be created interactively through the openshift-install create install-config command. The installer uses this configuration to create Kubernetes manifests and ignition configs for the virtual machines. In the case of installer-provisioned infrastructure, openshift-install uses Terraform to create the infrastructure for the cluster. For user-provisioned infrastructure, cloud-specific templates such as CloudFormation for AWS or ARM for Azure, are provided. For a more detailed overview of the Installer, please read the Installer Overview . For an overview of the general architecture of a cluster see the Architecture section of the official docs . For contributing to the Installer, please read the Contributor Guidelines . In particular, please note the guidelines regarding commit messages. Code contributions should be grouped into logically organized commits with clear commit messages. OWNERS files should be added in platform specific subdirectories. We recommend committing code to the Installer in the following order: pkg/types The types package is the API for the Installer. As such, it should not contain any external dependencies so that the package can be cleanly vendored to other repos. Adding Alibaba Platform openshift-install explain command ] pkg/assets: For the design behind assets in the installer, see the Asset Generation doc . A suggested approach for adding assets would be: pkg/assets/installconfig pkg/assets/manifests pkg/assets/machines Adding Alibaba Assets . Terraform Integration Integrate the Terraform provider by adding the plugin. Adding Stages and Terraform Variables for Alibaba . Terraform Configs Create the Terraform configurations at /data/data/{platform} . Alibaba Terraform Configuration . Destroy Add code to remove all resources created by the Installer and the cluster. The Installer should loop until all known resources are destroyed. Alibaba Destroy Code Documentation Add in-repo documentation, ideally following the general format of other platforms. AWS docs .","title":"Installer"},{"location":"installer/#installer","text":"The OpenShift Installer repo contains the code for the openshift-install Go binary as well as templates and documentation for user-provisioned infrastructure. openshift-install provides a user interface for the installation process on multiple cloud platforms. Users provide install configuration through an install-config.yaml file, which can be created interactively through the openshift-install create install-config command. The installer uses this configuration to create Kubernetes manifests and ignition configs for the virtual machines. In the case of installer-provisioned infrastructure, openshift-install uses Terraform to create the infrastructure for the cluster. For user-provisioned infrastructure, cloud-specific templates such as CloudFormation for AWS or ARM for Azure, are provided. For a more detailed overview of the Installer, please read the Installer Overview . For an overview of the general architecture of a cluster see the Architecture section of the official docs . For contributing to the Installer, please read the Contributor Guidelines . In particular, please note the guidelines regarding commit messages. Code contributions should be grouped into logically organized commits with clear commit messages. OWNERS files should be added in platform specific subdirectories. We recommend committing code to the Installer in the following order:","title":"Installer"},{"location":"installer/#pkgtypes","text":"The types package is the API for the Installer. As such, it should not contain any external dependencies so that the package can be cleanly vendored to other repos. Adding Alibaba Platform openshift-install explain command ]","title":"pkg/types"},{"location":"installer/#pkgassets","text":"For the design behind assets in the installer, see the Asset Generation doc . A suggested approach for adding assets would be: pkg/assets/installconfig pkg/assets/manifests pkg/assets/machines Adding Alibaba Assets .","title":"pkg/assets:"},{"location":"installer/#terraform-integration","text":"Integrate the Terraform provider by adding the plugin. Adding Stages and Terraform Variables for Alibaba .","title":"Terraform Integration"},{"location":"installer/#terraform-configs","text":"Create the Terraform configurations at /data/data/{platform} . Alibaba Terraform Configuration .","title":"Terraform Configs"},{"location":"installer/#destroy","text":"Add code to remove all resources created by the Installer and the cluster. The Installer should loop until all known resources are destroyed. Alibaba Destroy Code","title":"Destroy"},{"location":"installer/#documentation","text":"Add in-repo documentation, ideally following the general format of other platforms. AWS docs .","title":"Documentation"},{"location":"machine-api-controllers/","text":"Machine API Controllers The Machine API is OpenShift's declarative API for infrastructure provider compute resources. It is responsible for creating, destroying, and monitoring the machine instances (virtual machines, bare metal servers, etc.) that are configured for inclusion. In a standard Installer Provisioned Infrastructure (IPI) installation, the Machine API will include the instances of the compute plane, the control plane is not managed by the Machine API. In User Provisioned Infrastructure (UPI) installations, the Machine API may, or may not, be used depending on the configuration specified by the user. Components of Machine API There are several operators, controllers, and Custom Resource Definitions which define the Machine API. It is important to understand how these components interact before building a new infrastructure provider. Custom Resource Definitions The primary resources of the Machine API are Machines, MachineSets, and MachineHealthChecks. For the purposes of implementing a new infrastructure provider, Machines and MachineSets will be the resources that will require integration. Machines represent individual host instances within an infrastructure provider that will become Nodes in the OpenShift cluster. MachineSets are scalable collections of Machines. Within each MachineSet is a template for creating new Machines on the infrastructure. MachineHealthChecks are resources that are used to designate MachineSets which should automatically repair unhealthy Machines, and the conditions by which those Machine's health is determined. Machine API Operator The machine-api-operator (MAO) is the main entry point into the Machine API. The operator is responsible for deploying the infrastructure-specific Machine controller, and also runs controllers for MachineSets, and MachineHealthChecks. The MAO also deploys the validating and mutating webhooks for Machine resources. For more information about the Machine API Operator, please see the Machine API Operator Overview , and the Machine API Hacking Guide . Controllers owned by the Machine API Operator Machine controller - manages Machine resources. It uses an actuator interface , which follows a Machine lifecycle pattern . This interface provides Create , Update , Exists , and Delete methods to manage provider specific cloud instances, connected storage, and networking settings to make the instance prepared for bootstrapping. Each provider is therefore responsible for implementing these methods. MachineSet controller - manages MachineSet resources and ensures the presence of the expected number of replicas and a given provider config for a set of Machines. When increasing the replica count, this controller will use information in its ProviderSpec to create new Machines, copying that ProviderSpec to the Machine in the process. MachineHealthCheck controller - manages MachineHealthCheck resources. Ensure Machines being targeted by MachineHealthCheck objects are satisfying healthiness criteria or are remediated otherwise. For more information about MachineHealthChecks, please see the OpenShift Deploying machine health checks documentation. NodeLink controller - ensure Machines have a nodeRef based on providerID matching. Annotate nodes with a label containing the Machine name. Although the Machine API operator owns the lifecycle of all these controllers, it is worth noting that for new infrastructure providers only the Machine controller will require code changes. Machine API Webhooks The Machine API operator deploys mutating and validating webhooks for Machines and MachineSets. The webhooks allow the Machine API operator to detect invalid manifest declarations, or add values that are required by OpenShift. By using webhooks the Machine API operator is able to return warnings and errors to the user before the request is accepted by the Kubernetes API server. For more information about webhooks in Kubernetes, please see the Dynamic Admission Control documentation. In general, new infrastructure provider should not need to change the webhook configuration. Integrating with the Machine API Operator There are several steps involved with integrating a new infrastructure provider into the Machine API on OpenShift. The largest task will be creating the actuator which will do the work of creating, deleting, and updating infrastructure resources. Beyond that, there are some details around aligning the deployed release images, and the infrastrcuture detection within the MAO. Machine API CRDs and ProviderSpec MachineSets and Machines are the resources that describe the server instances within the infrastructure provider. Each MachineSet contains a Template field which declares how new Machines should be created by embedding a MachineSpec object. The MachineSpec contains a field named ProviderSpec , although this resource is not a CRD on its own, it is an embedded API type that allows each infrastructure provider to have a different set of variables to use when creating new Machines. While the MachineSet and Machine objects will not need to change to accomodate new infrastructure providers, the ProviderSpec will need to be created specifically for each new provider. For example here are the ProviderSpecs for Alibaba Cloud and IBM Cloud: ProviderSpec defined for Alibaba Cloud ProviderSpec defined for IBM Cloud When creating a new ProviderSpec it is natural to begin development with the API type defined within the repository for the new component (akin to the IBM Cloud example). Before final release the ProviderSpec API code should be moved to the openshift/api repository (similar to the Alibaba Cloud example). All new ProviderSpecs will be at API version v1 . The rationale for adding these types to the API repository is that it makes it easier to re-vendor those API types into other projects, and it promotes a more thorough API review process. Keep in mind that when adding changes to the API repository, all dependent repositories (for example installer) will need to be re-vendored after the API changes have merged. The following pull request is an example of how to integrate a new ProviderSpec into the API repository: Machine API: adding Alibaba cloud provider types #1045 Machine Controllers and Actuators As noted above, the Machine controller manages Machine resources. The Machine controller is also the interface between the MAO, the Machine API CRDs, and the infrastructure provider. The controller wraps the actuator interface which talks directly to the infrastructure provider. The actuator interface is the contact point between OpenShift's Machine API and a provider's infrastructure. This diagram illustrates the relationships: +----------+ +--------------------+ | Machine | reconciles | Machine controller | | Resource |<-------------| | +----------------+ +----------+ | +----------+ | communicates | | | | actuator |----+--------------->| Infrastructure | | +----------+ | | | +--------------------+ +----------------+ When writing a new actuator implementation, it is helpful to first start by looking at the controller wrapper which is provided by the MAO. The controller is defined in the controller.go file of the machine-api-operator repository. This controller is used by each infrastructure provider to associate its actuator code with the Machine reconciliation. The machine controller is designed to work with controller-runtime managers using the AddWithActuator method. For example, here is how the Machine controllers and actuators are configured for AWS and IBM Cloud: AWS Machine controller actuator configuration IBM Cloud Machine controller actuator configuration The majority of the work when implmenting a Machine controller for a new infrastructure provider will be satisfying the actuator interface defined by the MAO. The interface itself is small enough that it can be reproduced here: type Actuator interface { // Create the machine. Create(context.Context, *machinev1.Machine) error // Delete the machine. If no error is returned, it is assumed that all dependent resources have been cleaned up. Delete(context.Context, *machinev1.Machine) error // Update the machine to the provided definition. Update(context.Context, *machinev1.Machine) error // Checks if the machine currently exists. Exists(context.Context, *machinev1.Machine) (bool, error) } The following are two examples of Machine actuator implementations: AWS Machine actuator IBM Cloud Machine actuator MachineSet Controllers Infrastructure provider-specific MachineSet controllers are used to enable scale-from-zero features with the cluster autoscaler as described in this OpenShift enhancement on Autoscaling from/to zero . Unlike the Machine controller and actuator provided by the MAO, there is no corresponding helpers for implementing a MachineSet controller. The following are two examples of MachineSet controllers which implement scale from/to zero: AWS MachineSet controller IBM Cloud MachineSet controller Adding the new controllers to the Machine API operator With all the necessary controller code and repositories created, the final step for integration with the Machine API is adding the new infrastructure provider to the Machine API operator. This process involves adding a manifest for a cloud credential request, adding the container image references, and updating the operator to detect the new platform. These changes are best illustrated through example, the following pull request show the addition of the IBM Cloud provider to the Machine API operator. Take special note of the CredentialsRequest as this is the resource to encode provider-specific access roles. IBM Cloud provider addition to Machine API operator Integrating with OpenShift In addition to implementing the controllers and actuators for a new Machine API provider, the repository containing this code will need to be included in the OpenShift organization on GitHub. After adding the new repository to the organization, it will then need to be configured for continuous integration testing and image creation. Add Machine API provider repo to OpenShift For the highest levels of integration with OpenShift, it is recommended to copy the new infrastructure provider code repository to the OpenShift organization on GitHub. Migrating the code to this organization will help to ensure that the OpenShift continuous integration processes have full access to the source repository. To begin adding a new Machine API infrastructure provider repository the first step is the repository name. It should have a format of machine-api-provider-$PROVIDER_NAME , where $PROVIDER_NAME is replaced with the infrastructure name. For example, the AWS provider is machine-api-provider-aws . The repository will need to be copied into the OpenShift organization. This process is described in more detail in the Creating a GitHub Repository in the OpenShift Organization document. Having the source code in the OpenShift organization will allow Red Hat's continuous integration tooling access to it for running tests, building images, and including in the official releases. Configure basic repository integrations After setting up the code repository, there are several continuous integration tasks which must be done. This process is described in more detail in the Configuring Basic Repository Integrations document. As an example, here is the pull request to add the MAPI provider for IBM Cloud to the OpenShift Prow. It configures the Tide mechanics as well as pre-submit jobs to run the unit tests and check Go language formatting, and post-submit jobs to build the container images. openshift/release #19890 Relation to Cluster API The Machine API shares a common ancestry with the Cluster API project . In the early days of Cluster API development, the Machine API was solidified around the Machine and Machineset object definitions. Over time, the Machine API has continued to grow in accordance with the needs of OpenShift users. It is worth noting that the Machine API is not API compatible with the current versions of Cluster API.","title":"Machine API Controllers"},{"location":"machine-api-controllers/#machine-api-controllers","text":"The Machine API is OpenShift's declarative API for infrastructure provider compute resources. It is responsible for creating, destroying, and monitoring the machine instances (virtual machines, bare metal servers, etc.) that are configured for inclusion. In a standard Installer Provisioned Infrastructure (IPI) installation, the Machine API will include the instances of the compute plane, the control plane is not managed by the Machine API. In User Provisioned Infrastructure (UPI) installations, the Machine API may, or may not, be used depending on the configuration specified by the user.","title":"Machine API Controllers"},{"location":"machine-api-controllers/#components-of-machine-api","text":"There are several operators, controllers, and Custom Resource Definitions which define the Machine API. It is important to understand how these components interact before building a new infrastructure provider.","title":"Components of Machine API"},{"location":"machine-api-controllers/#custom-resource-definitions","text":"The primary resources of the Machine API are Machines, MachineSets, and MachineHealthChecks. For the purposes of implementing a new infrastructure provider, Machines and MachineSets will be the resources that will require integration. Machines represent individual host instances within an infrastructure provider that will become Nodes in the OpenShift cluster. MachineSets are scalable collections of Machines. Within each MachineSet is a template for creating new Machines on the infrastructure. MachineHealthChecks are resources that are used to designate MachineSets which should automatically repair unhealthy Machines, and the conditions by which those Machine's health is determined.","title":"Custom Resource Definitions"},{"location":"machine-api-controllers/#machine-api-operator","text":"The machine-api-operator (MAO) is the main entry point into the Machine API. The operator is responsible for deploying the infrastructure-specific Machine controller, and also runs controllers for MachineSets, and MachineHealthChecks. The MAO also deploys the validating and mutating webhooks for Machine resources. For more information about the Machine API Operator, please see the Machine API Operator Overview , and the Machine API Hacking Guide .","title":"Machine API Operator"},{"location":"machine-api-controllers/#controllers-owned-by-the-machine-api-operator","text":"Machine controller - manages Machine resources. It uses an actuator interface , which follows a Machine lifecycle pattern . This interface provides Create , Update , Exists , and Delete methods to manage provider specific cloud instances, connected storage, and networking settings to make the instance prepared for bootstrapping. Each provider is therefore responsible for implementing these methods. MachineSet controller - manages MachineSet resources and ensures the presence of the expected number of replicas and a given provider config for a set of Machines. When increasing the replica count, this controller will use information in its ProviderSpec to create new Machines, copying that ProviderSpec to the Machine in the process. MachineHealthCheck controller - manages MachineHealthCheck resources. Ensure Machines being targeted by MachineHealthCheck objects are satisfying healthiness criteria or are remediated otherwise. For more information about MachineHealthChecks, please see the OpenShift Deploying machine health checks documentation. NodeLink controller - ensure Machines have a nodeRef based on providerID matching. Annotate nodes with a label containing the Machine name. Although the Machine API operator owns the lifecycle of all these controllers, it is worth noting that for new infrastructure providers only the Machine controller will require code changes.","title":"Controllers owned by the Machine API Operator"},{"location":"machine-api-controllers/#machine-api-webhooks","text":"The Machine API operator deploys mutating and validating webhooks for Machines and MachineSets. The webhooks allow the Machine API operator to detect invalid manifest declarations, or add values that are required by OpenShift. By using webhooks the Machine API operator is able to return warnings and errors to the user before the request is accepted by the Kubernetes API server. For more information about webhooks in Kubernetes, please see the Dynamic Admission Control documentation. In general, new infrastructure provider should not need to change the webhook configuration.","title":"Machine API Webhooks"},{"location":"machine-api-controllers/#integrating-with-the-machine-api-operator","text":"There are several steps involved with integrating a new infrastructure provider into the Machine API on OpenShift. The largest task will be creating the actuator which will do the work of creating, deleting, and updating infrastructure resources. Beyond that, there are some details around aligning the deployed release images, and the infrastrcuture detection within the MAO.","title":"Integrating with the Machine API Operator"},{"location":"machine-api-controllers/#machine-api-crds-and-providerspec","text":"MachineSets and Machines are the resources that describe the server instances within the infrastructure provider. Each MachineSet contains a Template field which declares how new Machines should be created by embedding a MachineSpec object. The MachineSpec contains a field named ProviderSpec , although this resource is not a CRD on its own, it is an embedded API type that allows each infrastructure provider to have a different set of variables to use when creating new Machines. While the MachineSet and Machine objects will not need to change to accomodate new infrastructure providers, the ProviderSpec will need to be created specifically for each new provider. For example here are the ProviderSpecs for Alibaba Cloud and IBM Cloud: ProviderSpec defined for Alibaba Cloud ProviderSpec defined for IBM Cloud When creating a new ProviderSpec it is natural to begin development with the API type defined within the repository for the new component (akin to the IBM Cloud example). Before final release the ProviderSpec API code should be moved to the openshift/api repository (similar to the Alibaba Cloud example). All new ProviderSpecs will be at API version v1 . The rationale for adding these types to the API repository is that it makes it easier to re-vendor those API types into other projects, and it promotes a more thorough API review process. Keep in mind that when adding changes to the API repository, all dependent repositories (for example installer) will need to be re-vendored after the API changes have merged. The following pull request is an example of how to integrate a new ProviderSpec into the API repository: Machine API: adding Alibaba cloud provider types #1045","title":"Machine API CRDs and ProviderSpec"},{"location":"machine-api-controllers/#machine-controllers-and-actuators","text":"As noted above, the Machine controller manages Machine resources. The Machine controller is also the interface between the MAO, the Machine API CRDs, and the infrastructure provider. The controller wraps the actuator interface which talks directly to the infrastructure provider. The actuator interface is the contact point between OpenShift's Machine API and a provider's infrastructure. This diagram illustrates the relationships: +----------+ +--------------------+ | Machine | reconciles | Machine controller | | Resource |<-------------| | +----------------+ +----------+ | +----------+ | communicates | | | | actuator |----+--------------->| Infrastructure | | +----------+ | | | +--------------------+ +----------------+ When writing a new actuator implementation, it is helpful to first start by looking at the controller wrapper which is provided by the MAO. The controller is defined in the controller.go file of the machine-api-operator repository. This controller is used by each infrastructure provider to associate its actuator code with the Machine reconciliation. The machine controller is designed to work with controller-runtime managers using the AddWithActuator method. For example, here is how the Machine controllers and actuators are configured for AWS and IBM Cloud: AWS Machine controller actuator configuration IBM Cloud Machine controller actuator configuration The majority of the work when implmenting a Machine controller for a new infrastructure provider will be satisfying the actuator interface defined by the MAO. The interface itself is small enough that it can be reproduced here: type Actuator interface { // Create the machine. Create(context.Context, *machinev1.Machine) error // Delete the machine. If no error is returned, it is assumed that all dependent resources have been cleaned up. Delete(context.Context, *machinev1.Machine) error // Update the machine to the provided definition. Update(context.Context, *machinev1.Machine) error // Checks if the machine currently exists. Exists(context.Context, *machinev1.Machine) (bool, error) } The following are two examples of Machine actuator implementations: AWS Machine actuator IBM Cloud Machine actuator","title":"Machine Controllers and Actuators"},{"location":"machine-api-controllers/#machineset-controllers","text":"Infrastructure provider-specific MachineSet controllers are used to enable scale-from-zero features with the cluster autoscaler as described in this OpenShift enhancement on Autoscaling from/to zero . Unlike the Machine controller and actuator provided by the MAO, there is no corresponding helpers for implementing a MachineSet controller. The following are two examples of MachineSet controllers which implement scale from/to zero: AWS MachineSet controller IBM Cloud MachineSet controller","title":"MachineSet Controllers"},{"location":"machine-api-controllers/#adding-the-new-controllers-to-the-machine-api-operator","text":"With all the necessary controller code and repositories created, the final step for integration with the Machine API is adding the new infrastructure provider to the Machine API operator. This process involves adding a manifest for a cloud credential request, adding the container image references, and updating the operator to detect the new platform. These changes are best illustrated through example, the following pull request show the addition of the IBM Cloud provider to the Machine API operator. Take special note of the CredentialsRequest as this is the resource to encode provider-specific access roles. IBM Cloud provider addition to Machine API operator","title":"Adding the new controllers to the Machine API operator"},{"location":"machine-api-controllers/#integrating-with-openshift","text":"In addition to implementing the controllers and actuators for a new Machine API provider, the repository containing this code will need to be included in the OpenShift organization on GitHub. After adding the new repository to the organization, it will then need to be configured for continuous integration testing and image creation.","title":"Integrating with OpenShift"},{"location":"machine-api-controllers/#add-machine-api-provider-repo-to-openshift","text":"For the highest levels of integration with OpenShift, it is recommended to copy the new infrastructure provider code repository to the OpenShift organization on GitHub. Migrating the code to this organization will help to ensure that the OpenShift continuous integration processes have full access to the source repository. To begin adding a new Machine API infrastructure provider repository the first step is the repository name. It should have a format of machine-api-provider-$PROVIDER_NAME , where $PROVIDER_NAME is replaced with the infrastructure name. For example, the AWS provider is machine-api-provider-aws . The repository will need to be copied into the OpenShift organization. This process is described in more detail in the Creating a GitHub Repository in the OpenShift Organization document. Having the source code in the OpenShift organization will allow Red Hat's continuous integration tooling access to it for running tests, building images, and including in the official releases.","title":"Add Machine API provider repo to OpenShift"},{"location":"machine-api-controllers/#configure-basic-repository-integrations","text":"After setting up the code repository, there are several continuous integration tasks which must be done. This process is described in more detail in the Configuring Basic Repository Integrations document. As an example, here is the pull request to add the MAPI provider for IBM Cloud to the OpenShift Prow. It configures the Tide mechanics as well as pre-submit jobs to run the unit tests and check Go language formatting, and post-submit jobs to build the container images. openshift/release #19890","title":"Configure basic repository integrations"},{"location":"machine-api-controllers/#relation-to-cluster-api","text":"The Machine API shares a common ancestry with the Cluster API project . In the early days of Cluster API development, the Machine API was solidified around the Machine and Machineset object definitions. Over time, the Machine API has continued to grow in accordance with the needs of OpenShift users. It is worth noting that the Machine API is not API compatible with the current versions of Cluster API.","title":"Relation to Cluster API"},{"location":"network-ingress-dns/","text":"Network Ingress and DNS Network Ingress Ensure the cloud provider implementation has support for load balancers If OpenShift should manage load balancers for this platform, the cloud provider needs to implement the cloudprovider.LoadBalancer interface . Then the ingress operator needs to be updated to configure a load balancer service on this platform. For example: - add provider-specific annotations to InternalLBAnnotations and managedLoadBalancerServiceAnnotations - evaluate customizations needed for load balancer service configuration in desiredLoadBalancerService - add unit tests to catch regressions Evaluate ingress provider-specific support for load balancers Review the end-to-end tests in the operator tests and make customizations, or skip the tests for this provider if they don't apply. For example: - see TestProxyProtocolOnAWS for an example for the AWS cloud provider - check if you require TestInternalLoadBalancer , TestIngressControllerCustomEndpoints , TestLocalWithFallbackOverrideForLoadBalancerService for your platform - add unit tests to catch regressions Evaluate provider-specific endpoint publishing strategy Look through the doc at the custom resource definition to understand the details for endpointPublishingStrategy , which is the set of parameters used to publish the ingress controller endpoints to other networks, enable load balancer integrations, and other tasks. Understand the properties: - hostNetwork, loadBalancerService, nodePortService, private Check if customizations are needed in the ingress controller operator For example: - add your default strategy to setDefaultPublishingStrategy - add your integration for IsProxyProtocolNeeded - add unit tests to catch regressions Document the default endpoint publishing strategy for the provider DNS Evaluate provider-specific DNS support and validate the controller Check if customizations are needed in the ingress operator's DNS controller . For example: - define a new DNS provider - add your platform type to createDNSProvider , and createDNSProviderIfNeeded - add unit tests to catch regressions Evaluate provider-specific externalDNS support (4.10+) Starting in OpenShift 4.10, there is the External-DNS operator to consider. It will support only these platforms in 4.10: - AWS - GCP - Azure Questions Questions can be directed to the OpenShift Slack channel #forum-network-edge","title":"Network Ingress and DNS"},{"location":"network-ingress-dns/#network-ingress-and-dns","text":"","title":"Network Ingress and DNS"},{"location":"network-ingress-dns/#network-ingress","text":"","title":"Network Ingress"},{"location":"network-ingress-dns/#ensure-the-cloud-provider-implementation-has-support-for-load-balancers","text":"If OpenShift should manage load balancers for this platform, the cloud provider needs to implement the cloudprovider.LoadBalancer interface . Then the ingress operator needs to be updated to configure a load balancer service on this platform. For example: - add provider-specific annotations to InternalLBAnnotations and managedLoadBalancerServiceAnnotations - evaluate customizations needed for load balancer service configuration in desiredLoadBalancerService - add unit tests to catch regressions","title":"Ensure the cloud provider implementation has support for load balancers"},{"location":"network-ingress-dns/#evaluate-ingress-provider-specific-support-for-load-balancers","text":"Review the end-to-end tests in the operator tests and make customizations, or skip the tests for this provider if they don't apply. For example: - see TestProxyProtocolOnAWS for an example for the AWS cloud provider - check if you require TestInternalLoadBalancer , TestIngressControllerCustomEndpoints , TestLocalWithFallbackOverrideForLoadBalancerService for your platform - add unit tests to catch regressions","title":"Evaluate ingress provider-specific support for load balancers"},{"location":"network-ingress-dns/#evaluate-provider-specific-endpoint-publishing-strategy","text":"Look through the doc at the custom resource definition to understand the details for endpointPublishingStrategy , which is the set of parameters used to publish the ingress controller endpoints to other networks, enable load balancer integrations, and other tasks. Understand the properties: - hostNetwork, loadBalancerService, nodePortService, private Check if customizations are needed in the ingress controller operator For example: - add your default strategy to setDefaultPublishingStrategy - add your integration for IsProxyProtocolNeeded - add unit tests to catch regressions","title":"Evaluate provider-specific endpoint publishing strategy"},{"location":"network-ingress-dns/#document-the-default-endpoint-publishing-strategy-for-the-provider","text":"","title":"Document the default endpoint publishing strategy for the provider"},{"location":"network-ingress-dns/#dns","text":"","title":"DNS"},{"location":"network-ingress-dns/#evaluate-provider-specific-dns-support-and-validate-the-controller","text":"Check if customizations are needed in the ingress operator's DNS controller . For example: - define a new DNS provider - add your platform type to createDNSProvider , and createDNSProviderIfNeeded - add unit tests to catch regressions","title":"Evaluate provider-specific DNS support and validate the controller"},{"location":"network-ingress-dns/#evaluate-provider-specific-externaldns-support-410","text":"Starting in OpenShift 4.10, there is the External-DNS operator to consider. It will support only these platforms in 4.10: - AWS - GCP - Azure","title":"Evaluate provider-specific externalDNS support (4.10+)"},{"location":"network-ingress-dns/#questions","text":"Questions can be directed to the OpenShift Slack channel #forum-network-edge","title":"Questions"},{"location":"openshift-enhancement/","text":"OpenShift Enhancement Inspired by the Kubernetes community enhancement process, OpenShift also uses enhancements to drive and define its features. Early in the process of adding a new infrastructure provider to OpenShift, an enhancement document should be created to scope the work that is being done and to expose design details which might need modification on OpenShift. To begin, visit the OpenShift enhancements repository and become familiar with the enhancement template as well as the enhancement guidelines . When ready, create a pull request with your new infrastructure provider enhancement to the repository. To aid in this process, here are two examples of pull requests for recently added platforms: Alibaba Cloud platform enhancement pull request IBM Cloud platform enhancement pull request Writing the enhancement The enhancement template should guide you in organizing the text of your enhancement. But, it has been designed primarily for feature and code changes to OpenShift, so there are a few topics you should consider specifically while writing. What will an OpenShift cluster look like on the new infrastructure provider? (Adding a topology diagram can be very helpful to explain the logical architecture.) Are there special networking considerations that need to be explained (e.g. DNS and load balancing strategies)? What types of compute and storage are available on the infrastructure? How will users install and consume OpenShift on the infrastructure? The \"Drawbacks\" and \"Alternatives\" sections in the enhancement do not always make sense for new infrastructure providers. Depending on the options available for deploying OpenShift on the infrastructure, the \"Alternatives\" section can be a good place to talk about other methods of deployment.","title":"OpenShift Enhancement"},{"location":"openshift-enhancement/#openshift-enhancement","text":"Inspired by the Kubernetes community enhancement process, OpenShift also uses enhancements to drive and define its features. Early in the process of adding a new infrastructure provider to OpenShift, an enhancement document should be created to scope the work that is being done and to expose design details which might need modification on OpenShift. To begin, visit the OpenShift enhancements repository and become familiar with the enhancement template as well as the enhancement guidelines . When ready, create a pull request with your new infrastructure provider enhancement to the repository. To aid in this process, here are two examples of pull requests for recently added platforms: Alibaba Cloud platform enhancement pull request IBM Cloud platform enhancement pull request","title":"OpenShift Enhancement"},{"location":"openshift-enhancement/#writing-the-enhancement","text":"The enhancement template should guide you in organizing the text of your enhancement. But, it has been designed primarily for feature and code changes to OpenShift, so there are a few topics you should consider specifically while writing. What will an OpenShift cluster look like on the new infrastructure provider? (Adding a topology diagram can be very helpful to explain the logical architecture.) Are there special networking considerations that need to be explained (e.g. DNS and load balancing strategies)? What types of compute and storage are available on the infrastructure? How will users install and consume OpenShift on the infrastructure? The \"Drawbacks\" and \"Alternatives\" sections in the enhancement do not always make sense for new infrastructure providers. Depending on the options available for deploying OpenShift on the infrastructure, the \"Alternatives\" section can be a good place to talk about other methods of deployment.","title":"Writing the enhancement"},{"location":"preparation/","text":"Preparation Welcome, this documentation describes the engineering related processes for adding a new infrastructure provider to the OpenShift Container Platform. If you are reading this, then you are most likely either planning to create a new provider or are in the process of implementing your provider for OpenShift. This documentation is intended to address the engineering-specific issues related to the process, if you have questions about other aspects of this process (e.g. legal, marketing, etc.) then you should reach out to your Red Hat representatives with those questions. Starting the process To begin, read through this documentation making note of the various components that will need to be configured for OpenShift. You will need to assess how your infrastructure meets the various requirements of OpenShift, and identify where gaps in feature coverage might exist. If you are creating an infrastructure provider that will be included with OpenShift Container Platform then you should already have a representative from Red Hat who will be your primary contact for questions and help with this process. If you have not contacted Red Het yet, please reach out through this Red Hat Partner Connect page for more information.","title":"Preparation"},{"location":"preparation/#preparation","text":"Welcome, this documentation describes the engineering related processes for adding a new infrastructure provider to the OpenShift Container Platform. If you are reading this, then you are most likely either planning to create a new provider or are in the process of implementing your provider for OpenShift. This documentation is intended to address the engineering-specific issues related to the process, if you have questions about other aspects of this process (e.g. legal, marketing, etc.) then you should reach out to your Red Hat representatives with those questions.","title":"Preparation"},{"location":"preparation/#starting-the-process","text":"To begin, read through this documentation making note of the various components that will need to be configured for OpenShift. You will need to assess how your infrastructure meets the various requirements of OpenShift, and identify where gaps in feature coverage might exist. If you are creating an infrastructure provider that will be included with OpenShift Container Platform then you should already have a representative from Red Hat who will be your primary contact for questions and help with this process. If you have not contacted Red Het yet, please reach out through this Red Hat Partner Connect page for more information.","title":"Starting the process"},{"location":"procedures/configuring-repository-integrations/","text":"Configuring Basic Repository Integrations After the repository is copied to the OpenShift organization, there are a few basic continuous integration tasks that should be configured. The most important of these initially are the job to permit automated merging through Tide and the job to create container images on commits. OpenShift uses Prow for continuous integration testing much like the Kubernetes community does. The configurations are contained in the openshift/release repository. This is where pull requests will need to be made to enable integrations for the new CCM. For a deeper understanding of the OpenShift continuous integration tooling, the OpenShift CI Docs are the authoritative source. In specific for this initial task, the Bootstrapping Configuration for a new Repository should be used as a guide.","title":"Configuring Basic Repository Integrations"},{"location":"procedures/configuring-repository-integrations/#configuring-basic-repository-integrations","text":"After the repository is copied to the OpenShift organization, there are a few basic continuous integration tasks that should be configured. The most important of these initially are the job to permit automated merging through Tide and the job to create container images on commits. OpenShift uses Prow for continuous integration testing much like the Kubernetes community does. The configurations are contained in the openshift/release repository. This is where pull requests will need to be made to enable integrations for the new CCM. For a deeper understanding of the OpenShift continuous integration tooling, the OpenShift CI Docs are the authoritative source. In specific for this initial task, the Bootstrapping Configuration for a new Repository should be used as a guide.","title":"Configuring Basic Repository Integrations"},{"location":"procedures/creating-an-openshift-repository/","text":"Creating a GitHub Repository in the OpenShift Organization A common task when adding a new component to OpenShift is creating a GitHub repository in the OpenShift organization . This is where all the code that becomes part of an OpenShift release lives. To accomplish creating a new repository, a Red Hat representative will need to make a Jira request on the internal DPP Board . For infrastructure implementors: Contact your Red Hat representative about creating a new repository. Have the name, description, and license information for the new repository ready to share. If you would like to have the repository forked from an existing repository let your contact know this at the beginning of the process. For Red Hat representatives: See this internal documentation, How to Request a new OpenShift GitHub Repository","title":"Creating a GitHub Repository in the OpenShift Organization"},{"location":"procedures/creating-an-openshift-repository/#creating-a-github-repository-in-the-openshift-organization","text":"A common task when adding a new component to OpenShift is creating a GitHub repository in the OpenShift organization . This is where all the code that becomes part of an OpenShift release lives. To accomplish creating a new repository, a Red Hat representative will need to make a Jira request on the internal DPP Board . For infrastructure implementors: Contact your Red Hat representative about creating a new repository. Have the name, description, and license information for the new repository ready to share. If you would like to have the repository forked from an existing repository let your contact know this at the beginning of the process. For Red Hat representatives: See this internal documentation, How to Request a new OpenShift GitHub Repository","title":"Creating a GitHub Repository in the OpenShift Organization"},{"location":"red-hat-relationship/","text":"Red Hat Relationship Landing code in the OpenShift release is just one part of the integration journey. Once the initial work of integrating a new infrastructure platform is complete, there is extended task of maintainance and feature improvement. Depending on the depth of the partner agreement with Red Hat, it is reasonable to expect that there will be continuing work in the form of bug fixes and continued maintenance. In some cases, due to timing, it is possible that the initial work which lands in the release payload will need further engineering to reach the expected feature parity. Open source All components that are released by Red Hat are built using open source development practices. As such, the components that are included in OpenShift Container Platform releases will have their source code stored in a publicly accessible location (usually the OpenShift GitHub organization ). The open source development model encourages collaboration from the community of users who operate and utilize the software. This means that bugs can be reported by anyone, and likewise solutions can also be proposed by anyone in the community. The components that you build for OpenShift will be released as open source software. Once they are released, you have the opportunity to create fixes collaboratively and transparently with the community. This is a core principle to the continuing relationship with Red Hat and the wider user community. Bugzilla Red Hat uses Bugzilla as the primary point of interaction for reporting and tracking defects. Red Hat is also in the process if mirroring bugs from Bugzilla into a public Jira instance as well. In the future, Jira may become the primary interface, but for today you will need to use Bugzilla. Bugzilla workflow Bugs within Red Hat's bugzilla contain a state that indicates their current status. In general these states should flow from top to the bottom of the list following this paragraph. Engineers should never move bugs further down than MODIFIED state. Bug States NEW - only bugzillas with insufficient information (no reproducer, missing information from customer) and bugzillas where it is not sure who will take care of them (more people involved on the component) should be in this state. ASSIGNED - the most common bugzilla status, someone is assigned to the bugzilla and has enough information to further investigate and resolve the issue. POST - a patch or solution believed to resolve this matter has been proposed (POSTed) for inclusion to the appropriate git repo. MODIFIED - fix is in git, but was not tested yet and not released for users. The appropriate code repo has been MODIFIED with the fix. (This is the last state engineers should use.) If your PR properly linked to the BZ this should happen automatically. ON_QA - QA is looking at the fix. If it fails QA they will move it back to ASSIGNED. The 'automated release' team is responsible to move bugs from MODIFIED to ON_QA when the fix is available in a nightly build for testing. VERIFIED - QA tested the bugzilla and the bug seems to be fixed. RELEASE_PENDING - An errata was fully tested and the bug will get closed automatically once the images are publicly available. CLOSED - bugzilla is resolved, no further actions are needed (refer to bugzilla statuses for all variants of CLOSED). Reporting an OpenShift bug To report a new OpenShift bug, navigate to the Bugzilla webpage and file the bug by selecting \"New\", then \"Red Hat\", then \"OpenShift Container Platform\". The following link is a shortcut to create a new bug for the OpenShift Container Platform: New Bug for OpenShift Container Platform There are several fields to note when creating a new bug. The next few images will highlight the fields you need to fill. Bugzilla Field Descriptions Component is the OpenShift component to which the bug is being reported, for example Installer, or Cloud Compute. Choose the component which best fits the bug. Do not worry if you don't see an exact match for your component, choose the closest match and then during triage the bug will be re-assigned if necessary. If you know the GitHub repository of the component you are creating a bug against, you can look in the OWNERS file in the root of the repository to see the component information. Version is the OpenShift version against which this bug is being reported. By default this field will contain the version that is being released next. If reporting a bug to a previously released version of OpenShift, select that version. Target Release is the OpenShift version for which a solution is being proposed. This is used by Red Hat to indicate when engineering intends to fix a bug. It does not need to be set when creating a new bug. Severity is the impact that this bug has on OpenShift. You should set this field based on the nature of the bug as follows: Urgent - Causing a breakage/outage/unrecoverable issue. High - Blocking functionality from succeeding. Medium - Impacts functionality but critical operations remain functional or occurs under specific circumstances. Low - Everything else. Priority is set by Red Hat as a guideline for how the bug should be evaluated and planned. Priority should not be adjusted by anyone other than Red Hat component team members. Summary is a concise description of the bug. This is most frequently what users will see when searching for issues, so it should contain some high level identification of underlying problem. Description is where the bug will be described in greater detail. The template text in this field will guide you in creating content for the bug. New components in Bugzilla When adding new components to OpenShift, for example a new cloud controller manager, the new component will need to be added to Bugzilla by Red Hat team members. After you have completed the process of adding your repository to the OpenShift organization on GitHub and have created the necessary Prow configuration files in the OpenShift Release repository, your component should be added to Bugzilla. If you have completed these steps and do not see your component in Bugzilla, please reach out to your Red Hat contacts.","title":"Red Hat Relationship"},{"location":"red-hat-relationship/#red-hat-relationship","text":"Landing code in the OpenShift release is just one part of the integration journey. Once the initial work of integrating a new infrastructure platform is complete, there is extended task of maintainance and feature improvement. Depending on the depth of the partner agreement with Red Hat, it is reasonable to expect that there will be continuing work in the form of bug fixes and continued maintenance. In some cases, due to timing, it is possible that the initial work which lands in the release payload will need further engineering to reach the expected feature parity.","title":"Red Hat Relationship"},{"location":"red-hat-relationship/#open-source","text":"All components that are released by Red Hat are built using open source development practices. As such, the components that are included in OpenShift Container Platform releases will have their source code stored in a publicly accessible location (usually the OpenShift GitHub organization ). The open source development model encourages collaboration from the community of users who operate and utilize the software. This means that bugs can be reported by anyone, and likewise solutions can also be proposed by anyone in the community. The components that you build for OpenShift will be released as open source software. Once they are released, you have the opportunity to create fixes collaboratively and transparently with the community. This is a core principle to the continuing relationship with Red Hat and the wider user community.","title":"Open source"},{"location":"red-hat-relationship/#bugzilla","text":"Red Hat uses Bugzilla as the primary point of interaction for reporting and tracking defects. Red Hat is also in the process if mirroring bugs from Bugzilla into a public Jira instance as well. In the future, Jira may become the primary interface, but for today you will need to use Bugzilla.","title":"Bugzilla"},{"location":"red-hat-relationship/#bugzilla-workflow","text":"Bugs within Red Hat's bugzilla contain a state that indicates their current status. In general these states should flow from top to the bottom of the list following this paragraph. Engineers should never move bugs further down than MODIFIED state. Bug States NEW - only bugzillas with insufficient information (no reproducer, missing information from customer) and bugzillas where it is not sure who will take care of them (more people involved on the component) should be in this state. ASSIGNED - the most common bugzilla status, someone is assigned to the bugzilla and has enough information to further investigate and resolve the issue. POST - a patch or solution believed to resolve this matter has been proposed (POSTed) for inclusion to the appropriate git repo. MODIFIED - fix is in git, but was not tested yet and not released for users. The appropriate code repo has been MODIFIED with the fix. (This is the last state engineers should use.) If your PR properly linked to the BZ this should happen automatically. ON_QA - QA is looking at the fix. If it fails QA they will move it back to ASSIGNED. The 'automated release' team is responsible to move bugs from MODIFIED to ON_QA when the fix is available in a nightly build for testing. VERIFIED - QA tested the bugzilla and the bug seems to be fixed. RELEASE_PENDING - An errata was fully tested and the bug will get closed automatically once the images are publicly available. CLOSED - bugzilla is resolved, no further actions are needed (refer to bugzilla statuses for all variants of CLOSED).","title":"Bugzilla workflow"},{"location":"red-hat-relationship/#reporting-an-openshift-bug","text":"To report a new OpenShift bug, navigate to the Bugzilla webpage and file the bug by selecting \"New\", then \"Red Hat\", then \"OpenShift Container Platform\". The following link is a shortcut to create a new bug for the OpenShift Container Platform: New Bug for OpenShift Container Platform There are several fields to note when creating a new bug. The next few images will highlight the fields you need to fill. Bugzilla Field Descriptions Component is the OpenShift component to which the bug is being reported, for example Installer, or Cloud Compute. Choose the component which best fits the bug. Do not worry if you don't see an exact match for your component, choose the closest match and then during triage the bug will be re-assigned if necessary. If you know the GitHub repository of the component you are creating a bug against, you can look in the OWNERS file in the root of the repository to see the component information. Version is the OpenShift version against which this bug is being reported. By default this field will contain the version that is being released next. If reporting a bug to a previously released version of OpenShift, select that version. Target Release is the OpenShift version for which a solution is being proposed. This is used by Red Hat to indicate when engineering intends to fix a bug. It does not need to be set when creating a new bug. Severity is the impact that this bug has on OpenShift. You should set this field based on the nature of the bug as follows: Urgent - Causing a breakage/outage/unrecoverable issue. High - Blocking functionality from succeeding. Medium - Impacts functionality but critical operations remain functional or occurs under specific circumstances. Low - Everything else. Priority is set by Red Hat as a guideline for how the bug should be evaluated and planned. Priority should not be adjusted by anyone other than Red Hat component team members. Summary is a concise description of the bug. This is most frequently what users will see when searching for issues, so it should contain some high level identification of underlying problem. Description is where the bug will be described in greater detail. The template text in this field will guide you in creating content for the bug.","title":"Reporting an OpenShift bug"},{"location":"red-hat-relationship/#new-components-in-bugzilla","text":"When adding new components to OpenShift, for example a new cloud controller manager, the new component will need to be added to Bugzilla by Red Hat team members. After you have completed the process of adding your repository to the OpenShift organization on GitHub and have created the necessary Prow configuration files in the OpenShift Release repository, your component should be added to Bugzilla. If you have completed these steps and do not see your component in Bugzilla, please reach out to your Red Hat contacts.","title":"New components in Bugzilla"},{"location":"release/","text":"Release Red Hat releases new minor versions of OpenShift Container Platform approximately once every 4 months. OpenShift versions use a Semantic Versioning style of denotation to designate specific versions. For example, version \"4.8.1\" of OpenShift would designate that the major version is \"4\", the minor version is \"8\", and the patch level is \"1\". OpenShift is currently releasing along the major version \"4\" series. When the next version of OpenShift is released, it will be \"4.n+1\", where \"n\" is the current minor version. For example, at the time of writing the current version of OpenShift is \"4.9\", the next release will then be \"4.10\". Z-Stream Releases While new minor versions of OpenShift are released every 4 months, \"Z-Stream\" releases are created much more frequently to address security and critical bug fixes. A z-stream release is designated by an increase in the patch level version of the release. For example, version \"4.8.1\" of OpenShift would designate that the current patch level is \"1\", if a new z-stream release is needed it will be version \"4.8.2\". In general, backports to older versions of OpenShift will be evaluated on a case-by-case basis. Security and critical bug fixes will be considered the highest priority for backporting. Features are not backported without a justified exception from Red Hat. Integrating with the Release Process For any minor version of OpenShift the release process consists of several important phases which are traversed in this manner: Feature Development -> Feature Freeze -> Code Freeze -> General Availability Feature Development The feature development phase is a time when any change can be proposed to the code repositories. There are no automated limitations on the pull requests that can be proposed, and any work related to new features can be considered for inclusion. Ideally, the bulk of new work will be created during this phase of development. Feature Freeze Feature freeze is an important concept to understand when integrating with the Red Hat release process. During the development of a new version of OpenShift there will come a time when new feature work will be disallowed into the code base. This process is referred to as \"feature freeze\" and it is used to create a hard deadline for adding new features to a release. As new infrastructure platforms are considered features, new components and changes should be in place before the feature freeze. Approximately 12 weeks before the general availability release for an OpenShift version, the engineering team will observe the feature freeze. After the feature freeze date, new pull requests will require a related bugzilla issue in order to be considered for merging. This is not a mechanism for bringing features in though, and should only be used to fix bugs within the existing code. What this means is that new infrastructure providers should work to ensure their provider specific components have been created and included in continuous integration before the feature freeze. There will still be time to fix bugs, but the major pieces should be in place (e.g. repositories created, continuous integration configured, image builds automated). Code Freeze Approximately 6 weeks after feature freeze the OpenShift engineering team will observe a \"code freeze\". The code freeze indicates that no more pull requests will be taken from the source repositories, and that the release teams will now take over the process of performing the final testing and analysis, and packaging of release artifacts. During the time between the feature freeze and the code freeze, new pull requests will be accepted provided they have a related bugzilla issue. After code freeze these changes will not be considered or accepted unless they are release blocking issues. General Availability Once the source base that was compiled during the code freeze has been fully tested and vetted by the Red Hat release teams, the new OpenShift Container Platform version will be released for general availability. This process is usually predicted to occur 6 weeks after the code freeze, but given the possibility of release blocking bugs this is only an approximation. If you have followed the instructions in this guide then your new components will be ready for inclusion with the next OpenShift minor release. The final piece necessary for being included in an OpenShift release from Red Hat are full end-to-end integration of your infrastructure platform into the continuous integration process (this is covered in greater detail in Continuous Integration and Testing ). When the end-to-end integration tests of the new infrastructure platform are passing regularly, the new platform can be included in an OpenShift release. The new components will have already been included in nightly and continuous integration payloads, and they will now be promoted to the release payload. Release Life Cycle After release, Red Hat provides a support and maintenance life cycle for the version of OpenShift Container Platform depending on the release type and version number. For more information about this process and the dates associated with extended support, please see the Red Hat OpenShift Container Platform Life Cycle Policy document. For some historical context around the release schedule and how Red Hat has arrived at this process, please see the following articles: Time Is On Your Side: A Change to the OpenShift 4 Lifecycle The Ultimate Guide to OpenShift Release and Upgrade Process for Cluster Administrators","title":"Release"},{"location":"release/#release","text":"Red Hat releases new minor versions of OpenShift Container Platform approximately once every 4 months. OpenShift versions use a Semantic Versioning style of denotation to designate specific versions. For example, version \"4.8.1\" of OpenShift would designate that the major version is \"4\", the minor version is \"8\", and the patch level is \"1\". OpenShift is currently releasing along the major version \"4\" series. When the next version of OpenShift is released, it will be \"4.n+1\", where \"n\" is the current minor version. For example, at the time of writing the current version of OpenShift is \"4.9\", the next release will then be \"4.10\".","title":"Release"},{"location":"release/#z-stream-releases","text":"While new minor versions of OpenShift are released every 4 months, \"Z-Stream\" releases are created much more frequently to address security and critical bug fixes. A z-stream release is designated by an increase in the patch level version of the release. For example, version \"4.8.1\" of OpenShift would designate that the current patch level is \"1\", if a new z-stream release is needed it will be version \"4.8.2\". In general, backports to older versions of OpenShift will be evaluated on a case-by-case basis. Security and critical bug fixes will be considered the highest priority for backporting. Features are not backported without a justified exception from Red Hat.","title":"Z-Stream Releases"},{"location":"release/#integrating-with-the-release-process","text":"For any minor version of OpenShift the release process consists of several important phases which are traversed in this manner: Feature Development -> Feature Freeze -> Code Freeze -> General Availability","title":"Integrating with the Release Process"},{"location":"release/#feature-development","text":"The feature development phase is a time when any change can be proposed to the code repositories. There are no automated limitations on the pull requests that can be proposed, and any work related to new features can be considered for inclusion. Ideally, the bulk of new work will be created during this phase of development.","title":"Feature Development"},{"location":"release/#feature-freeze","text":"Feature freeze is an important concept to understand when integrating with the Red Hat release process. During the development of a new version of OpenShift there will come a time when new feature work will be disallowed into the code base. This process is referred to as \"feature freeze\" and it is used to create a hard deadline for adding new features to a release. As new infrastructure platforms are considered features, new components and changes should be in place before the feature freeze. Approximately 12 weeks before the general availability release for an OpenShift version, the engineering team will observe the feature freeze. After the feature freeze date, new pull requests will require a related bugzilla issue in order to be considered for merging. This is not a mechanism for bringing features in though, and should only be used to fix bugs within the existing code. What this means is that new infrastructure providers should work to ensure their provider specific components have been created and included in continuous integration before the feature freeze. There will still be time to fix bugs, but the major pieces should be in place (e.g. repositories created, continuous integration configured, image builds automated).","title":"Feature Freeze"},{"location":"release/#code-freeze","text":"Approximately 6 weeks after feature freeze the OpenShift engineering team will observe a \"code freeze\". The code freeze indicates that no more pull requests will be taken from the source repositories, and that the release teams will now take over the process of performing the final testing and analysis, and packaging of release artifacts. During the time between the feature freeze and the code freeze, new pull requests will be accepted provided they have a related bugzilla issue. After code freeze these changes will not be considered or accepted unless they are release blocking issues.","title":"Code Freeze"},{"location":"release/#general-availability","text":"Once the source base that was compiled during the code freeze has been fully tested and vetted by the Red Hat release teams, the new OpenShift Container Platform version will be released for general availability. This process is usually predicted to occur 6 weeks after the code freeze, but given the possibility of release blocking bugs this is only an approximation. If you have followed the instructions in this guide then your new components will be ready for inclusion with the next OpenShift minor release. The final piece necessary for being included in an OpenShift release from Red Hat are full end-to-end integration of your infrastructure platform into the continuous integration process (this is covered in greater detail in Continuous Integration and Testing ). When the end-to-end integration tests of the new infrastructure platform are passing regularly, the new platform can be included in an OpenShift release. The new components will have already been included in nightly and continuous integration payloads, and they will now be promoted to the release payload.","title":"General Availability"},{"location":"release/#release-life-cycle","text":"After release, Red Hat provides a support and maintenance life cycle for the version of OpenShift Container Platform depending on the release type and version number. For more information about this process and the dates associated with extended support, please see the Red Hat OpenShift Container Platform Life Cycle Policy document. For some historical context around the release schedule and how Red Hat has arrived at this process, please see the following articles: Time Is On Your Side: A Change to the OpenShift 4 Lifecycle The Ultimate Guide to OpenShift Release and Upgrade Process for Cluster Administrators","title":"Release Life Cycle"},{"location":"rhcos/","text":"RHCOS Platform Support To support a new platform one of the main requirements is to have Red Hat Enterprise Linux CoreOS (RHCOS) operating system work on the platform for provisioning the machines. This getting started guide gives a good overview of the Fedora CoreOS (FCOS) operating system and way to provision machines on different platforms. The process of building RHCOS and FCOS is largely the same except for the packages contained inside of the OS itself (RHEL vs Fedora). File a ticket for new platform support Please make sure to file a ticket against Fedora-CoreOS-Tracker by filing a new issue and choosing the Request a new platform option. Some important questions to be thought about/answered in the platform request tracker are: The official name of the platform - the name by which Ignition will identify the platform. Note that this can be different from the platform name used by the Openshift APIs How is userdata provided - this refers to how Ignition configuration is provided for this platform. How is the hostname provided - the method through which the machine gets its hostname. this could be through dhcp or a service like afterburn How is network configuration provided - the method through which network is configured - through DHCP or static ips provided in the metadata which can be accessed through services like afterburn How are ssh keys provided Details of the VM image which is to be built and published - this includes things like APIs to upload VM images, the disk format specification, etc.. Any new platform being added should first support FCOS (Fedora CoreOS) making sure that once the platform is fully supported that there are regular upstream CI jobs run to test FCOS and publish FCOS images. Support for building and publishing disk images If you are looking into building and publishing new disk images, you need to start with looking at the coreos-assembler tool. The coreos-assembler is a collection of tools inside a containerized build environment which is used to build and publish FCOS and RHCOS images. Some useful links on how to develop and use the coreos assembler: Working with CoreOS Assembler guide Building Fedora CoreOS Working on CoreOS Assembler guide CoreOS Assembler Design In addition, there are tools that help you test your image locally and also help you upload your images to the cloud. Mantle inside the coreos-assembler has a bunch of tools which help with different things: kola - for launching instances and running tests kolet - an agent for kola that runs on instances ore - for interfacing with cloud providers Ignition support Ignition is a utility that configures the machine. A list of supported platforms and how they provide the configuration to Ignition is listed here . Whenever a new platform is added, corresponding code must be added to specify the way to fetch configuration for the platform. Afterburn support Afterburn is used to implement cloud provider specific functionality by interacting with its metadata endpoints. It can be used to optionally set things like hostname and also inject network kernel command line arguments. In addition, it is also used to retrieve attributes from the metadata. Once added, some of this functionality can be enabled as systemd units in the Machine Config Operator. Questions Questions can be directed to these various communication channels for Fedora CoreOS","title":"RHCOS"},{"location":"rhcos/#rhcos-platform-support","text":"To support a new platform one of the main requirements is to have Red Hat Enterprise Linux CoreOS (RHCOS) operating system work on the platform for provisioning the machines. This getting started guide gives a good overview of the Fedora CoreOS (FCOS) operating system and way to provision machines on different platforms. The process of building RHCOS and FCOS is largely the same except for the packages contained inside of the OS itself (RHEL vs Fedora).","title":"RHCOS Platform Support"},{"location":"rhcos/#file-a-ticket-for-new-platform-support","text":"Please make sure to file a ticket against Fedora-CoreOS-Tracker by filing a new issue and choosing the Request a new platform option. Some important questions to be thought about/answered in the platform request tracker are: The official name of the platform - the name by which Ignition will identify the platform. Note that this can be different from the platform name used by the Openshift APIs How is userdata provided - this refers to how Ignition configuration is provided for this platform. How is the hostname provided - the method through which the machine gets its hostname. this could be through dhcp or a service like afterburn How is network configuration provided - the method through which network is configured - through DHCP or static ips provided in the metadata which can be accessed through services like afterburn How are ssh keys provided Details of the VM image which is to be built and published - this includes things like APIs to upload VM images, the disk format specification, etc.. Any new platform being added should first support FCOS (Fedora CoreOS) making sure that once the platform is fully supported that there are regular upstream CI jobs run to test FCOS and publish FCOS images.","title":"File a ticket for new platform support"},{"location":"rhcos/#support-for-building-and-publishing-disk-images","text":"If you are looking into building and publishing new disk images, you need to start with looking at the coreos-assembler tool. The coreos-assembler is a collection of tools inside a containerized build environment which is used to build and publish FCOS and RHCOS images. Some useful links on how to develop and use the coreos assembler: Working with CoreOS Assembler guide Building Fedora CoreOS Working on CoreOS Assembler guide CoreOS Assembler Design In addition, there are tools that help you test your image locally and also help you upload your images to the cloud. Mantle inside the coreos-assembler has a bunch of tools which help with different things: kola - for launching instances and running tests kolet - an agent for kola that runs on instances ore - for interfacing with cloud providers","title":"Support for building and publishing disk images"},{"location":"rhcos/#ignition-support","text":"Ignition is a utility that configures the machine. A list of supported platforms and how they provide the configuration to Ignition is listed here . Whenever a new platform is added, corresponding code must be added to specify the way to fetch configuration for the platform.","title":"Ignition support"},{"location":"rhcos/#afterburn-support","text":"Afterburn is used to implement cloud provider specific functionality by interacting with its metadata endpoints. It can be used to optionally set things like hostname and also inject network kernel command line arguments. In addition, it is also used to retrieve attributes from the metadata. Once added, some of this functionality can be enabled as systemd units in the Machine Config Operator.","title":"Afterburn support"},{"location":"rhcos/#questions","text":"Questions can be directed to these various communication channels for Fedora CoreOS","title":"Questions"}]}